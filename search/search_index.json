{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Lind-Wasm","text":"<p>Lind is a single-process sandbox that provides an option to safely execute programs. Lind executes applications using software fault isolation and a kernel microvisor to limit the potential of reaching bugs or security flaws in the application.</p> <p>In Old Norse, Old High German and Old English a \"lind\" is a shield constructed with two layers of linden wood. Linden wood shields are lightweight, and do not split easily, an appropriate metaphor for a sandboxing system which employs two technologies.</p>"},{"location":"#core-concepts","title":"Core Concepts","text":"<ul> <li>Cage: Lightweight isolation boundary within a process<ul> <li>Can run legacy code (may need recompilation)</li> <li>Protects and isolates memory</li> </ul> </li> <li>Microvisor: Small POSIX compliant kernel within a process<ul> <li>Provides a POSIX interface</li> <li>Distinct isolation between cages</li> </ul> </li> <li>3i (three eye): Capability-based POSIX interfaces between cages</li> </ul>"},{"location":"#technology-overview","title":"Technology Overview","text":""},{"location":"#cages","title":"Cages","text":"<p>Memory and bookkeeping that encapsulates the idea of a typical OS process, encompassing applications as well as grates.</p>"},{"location":"#grates","title":"Grates","text":"<p>Can perform trusted operations on descendant cages without requiring code in the microvisor's TCB. Grates can run arbitrary code, with restrictions only placed by grates beneath them. The microvisor implements a grate with access to call into the Linux kernel.</p> <p>Inheritance Properties:</p> <ul> <li>A child inherits system calls from parent on fork</li> <li>If cage A was forked by cage B, cage A will have the same system call handlers as cage B</li> <li>If grate A was forkinterpose()'d by grate B, grate A inherits B's system call behavior changes</li> </ul>"},{"location":"#3i-system","title":"3i System","text":"<p>The 3i system serves as:</p> <ul> <li>Central point for all communication between cages</li> <li>Table container for system call routing</li> <li>Security control mechanism for system call interception</li> <li>Privilege management system for blocking unnecessary calls</li> </ul>"},{"location":"#components","title":"Components","text":""},{"location":"#wasmtime","title":"Wasmtime","text":"<p>Wasmtime is a fast and secure runtime for WebAssembly designed by Bytecode Alliance. Lind-wasm uses wasmtime as a runtime with added support for multi-processing via Asyncify.</p>"},{"location":"#lind-glibc","title":"lind-glibc","text":"<p>We\u2019ve ported glibc so that it can be compiled to wasm bytecode and linked with any wasm binary. This includes minor changes like replacing assembly code, and add a mechansim to transfer system calls to the trusted runtime and microvisor.</p>"},{"location":"#rawposix","title":"RawPOSIX","text":"<p>Provides normal POSIX system calls including:</p> <ul> <li>Signals</li> <li>Fork/exec</li> <li>Threading</li> <li>File system</li> <li>Networking</li> <li>Separate handling of cages' fds and threads</li> </ul>"},{"location":"#3i-implementation","title":"3i Implementation","text":"<p>The iPC (intra-process call) interposable interface enables secure and efficient cage communication with function call-like speed. It provides POSIX interfaces between cages with interposition capabilities, enabling fine-grained security and access control while maintaining program behavior.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<ol> <li>Make sure to read the Basics first.</li> <li>If you want to start contributing, check out the Contributor Instructions.</li> <li>Continue reading to run a Hello World program in the Lind Sandbox.</li> </ol>"},{"location":"getting-started/#hello-world","title":"Hello World!","text":"<p>1. Set up the environment</p> <p>Run the following commands in your terminal to download and shell into an environment that comes with the Lind Sandbox. You'll need Docker installed.</p> <pre><code>docker pull --platform=linux/amd64 securesystemslab/lind-wasm  # this might take a while ...\ndocker run --platform=linux/amd64 -it securesystemslab/lind-wasm /bin/bash\n</code></pre> <p>There is a development environment with tooling and source code available, instructions to be found here</p> <p>2. Write a program</p> <p>In the same terminal, use e.g. <code>vi</code> to write a <code>hello.c</code> program to be executed in the Lind sandbox. You can also just paste the snippet below.</p> <pre><code>cat &lt;&lt; EOF &gt; hello.c\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"Hello, World!\\n\");\n    return 0;\n}\nEOF\n</code></pre> <p>3. Compile and run</p> <p>Use lind scripts to compile and run your program in the Lind Sandbox.</p> <pre><code>lind-clang hello.c\nlind-wasm hello.cwasm\n</code></pre> <p>Here is what happens under the hood:</p> <ol> <li><code>lind_compile</code> compiles <code>hello.c</code> into a WebAssembly (WASM) binary using headers etc. from lind-glibc.</li> <li><code>lind_run</code> runs the compiled wasm using lind-wasm runtime and the lind-posix microvisor.</li> </ol>"},{"location":"getting-started/#whats-next","title":"What's next!","text":"<p>The Lind documentation is currently under heavy construction. Please submit an issue, if something doesn't seem right or is missing. More detailed usage guides will follow soon!</p>"},{"location":"community/","title":"Community","text":"<p>Join #lind on the NYU Secure Systems Lab Slack to receive updates about the project and upcoming events, or dial in on a community meeting! Details are listed below and on Google Calendar.</p>"},{"location":"community/#meetings","title":"Meetings","text":""},{"location":"community/#governance-committee","title":"Governance Committee","text":"<ul> <li>Weekly on Friday 15:00 - 16:00 ET</li> <li>Zoom</li> <li>Meeting notes</li> </ul>"},{"location":"community/#tech-talks","title":"Tech Talks","text":"<ul> <li>Every 2 weeks on Friday 13:00 - 14:00 ET</li> <li>Zoom</li> <li>Meeting notes</li> </ul>"},{"location":"community/#maintainers-evaluation-benchmarking-wg","title":"Maintainers, Evaluation, &amp; Benchmarking WG","text":"<ul> <li>Every 2 weeks on Thursday 13:00 - 14:00 ET</li> <li>Zoom</li> <li>Meeting notes</li> </ul>"},{"location":"community/conduct/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"community/conduct/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"community/conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the overall   community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or advances of   any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email address,   without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"community/conduct/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"community/conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official email address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"community/conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at lind-project-reporting@googlegroups.com. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"community/conduct/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"community/conduct/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"community/conduct/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"community/conduct/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"community/conduct/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"community/conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"community/team/","title":"Lind-WASM Team","text":""},{"location":"community/team/#advisor","title":"Advisor","text":"Justin Cappos  Professor, NYU  GitHub Email"},{"location":"community/team/#maintainers","title":"Maintainers","text":"Nick Renner  PhD Candidate, NYU  GitHub Email Yuchen (Dennis) Zhang  Post-doctoral researcher, NYU  GitHub Email Yaxuan (Alice) Wen  PhD Student, NYU  GitHub Email Qianxi Chen  Undergraduate Research Lead, NYU  GitHub Email"},{"location":"community/team/#outside-collaborators","title":"Outside Collaborators","text":"Marcela Melara  Intel Labs  GitHub Email"},{"location":"contribute/","title":"Contributing","text":"<p>The Lind sandbox is developed in the lind-wasm monorepo on GitHub. You can find the documentation assets, including this site, in the <code>lind-wasm/docs</code> subdirectory. Please contribute to the Lind project by submitting issues or pull requests to these repositories.</p> <p>To report a security issue, please refer to the Security Policy!</p> <p>Continue reading the pages in this section for detailed guidelines about writing code, tests, documentation, and more.</p>"},{"location":"contribute/add-docs/","title":"How to Add Documentation","text":"<p>Built with mkdocs and material, and hosted on GitHub pages: lind-project.github.io/lind-wasm.</p> <p>You can improve the docs by editing the files below. See <code>mkdocs</code> and <code>material</code> user guides for details. And don't forget to try out your changes locally!</p>"},{"location":"contribute/add-docs/#important-files","title":"Important files","text":"<ul> <li><code>.github/workflows/docs.yml</code>: Auto-deploys on push to <code>main</code> (e.g. on PR merge)</li> <li><code>mkdocs.yml</code>: Site config (e.g. navigation and plugins)</li> <li><code>docs/</code>: Site sources</li> </ul>"},{"location":"contribute/add-docs/#build-site-locally","title":"Build site locally","text":"<pre><code># Install requirements (hint: use a virtual environment)\npip install mkdocs-material\n\n# Run dev server and check output!\nmkdocs serve\n</code></pre> <p>Note</p> <p>Please also document your implementation source code following the used programming language's standards.</p>"},{"location":"contribute/debug-programs/","title":"Debugging","text":""},{"location":"contribute/debug-programs/#debugging-with-gdb","title":"Debugging with GDB","text":"<p>To debug a WebAssembly module using GDB, ensure that your module is compiled with debugging information (e.g., using the -g flag during compilation). Additionally, Wasmtime itself must be compiled in debug mode (i.e., without the --release flag) to enable effective debugging of both the runtime and the module. This allows GDB to access symbol information from both your program and Wasmtime.</p> <p>Note: Current limitations in GDB support for WebAssembly include lack of instruction-level inspection. Commands like <code>layout split</code> and <code>si</code> (step instruction) may break the terminal. It\u2019s recommended to use <code>layout src</code> for source-level debugging.</p>"},{"location":"contribute/debug-programs/#running-gdb-with-wasmtime","title":"Running GDB with Wasmtime","text":"<p>Use the following command to start GDB with Wasmtime:</p> <pre><code>gdb --args ../wasmtime/target/debug/wasmtime run -D debug-info -O opt-level=0 malloc-test.wasm\n</code></pre> <p>Explanation of arguments:</p> <ul> <li><code>gdb --args</code>: Passes arguments to the program through GDB.</li> <li><code>../wasmtime/target/debug/wasmtime run</code>: Runs your WebAssembly module using the Wasmtime binary.</li> <li><code>-D debug-info</code>: Enables Wasmtime\u2019s debug information support.</li> <li><code>-O opt-level=0</code>: Disables optimizations for easier debugging.</li> </ul>"},{"location":"contribute/debug-programs/#example-debugging-session","title":"Example Debugging Session","text":"<ol> <li> <p>Start GDB    Launch GDB with Wasmtime and your WebAssembly module:    <pre><code>gdb --args ../wasmtime/target/debug/wasmtime run -D debug-info -O opt-level=0 malloc-test.wasm\n</code></pre></p> </li> <li> <p>Set Breakpoints    In the GDB prompt, set breakpoints as needed:    <pre><code>(gdb) break main\n</code></pre></p> </li> <li> <p>Run the Program    Start execution:    <pre><code>(gdb) run\n</code></pre></p> </li> <li> <p>Inspect and Debug    Use GDB commands to step through and inspect your code:    <pre><code>(gdb) next\n(gdb) print p\n(gdb) continue\n</code></pre></p> </li> </ol>"},{"location":"contribute/debug-programs/#additional-resources","title":"Additional Resources","text":"<ul> <li>Wasmtime Documentation</li> <li>GDB Manual</li> </ul>"},{"location":"contribute/debug-programs/#other-debugging-techniques","title":"Other Debugging Techniques","text":""},{"location":"contribute/debug-programs/#disabling-signals-for-debugging","title":"Disabling Signals for Debugging","text":"<p>The <code>signal-disable</code> feature added in this PR allows <code>lind-wasm</code> to run binaries without inserting Wasmtime epoch signals, which is useful for debugging purposes. When this feature is enabled, the signal handler is not set, and any unexpected signals (e.g., timeouts or faults) will cause the program to crash directly in RawPOSIX, making issues easier to trace.</p> <p>\u26a0\ufe0f Warning: This feature is intended for debugging only and should not be used in production environments.</p> <p>To use this feature, compile <code>lind-wasm</code> with the <code>signal-disable</code> feature enabled. Here\u2019s how to do it:</p> <p>Building with the Feature:</p> <p>From the root of the repository, navigate to <code>src/wasmtime</code> and build with the <code>signal-disable</code> feature:</p> <pre><code>cd src/wasmtime\n\n# Build lind-wasm with the signal-disable feature\ncargo build --features signal-disable\n</code></pre>"},{"location":"contribute/dev-container/","title":"Development setup","text":"<p>To access an environment with the source code and tooling, there is a development image available as well. (Note: If you intend to use perf, you will need to install the appropriate <code>linux-tools-xxx</code> for your kernel)</p> <pre><code>docker pull --platform=linux/amd64 securesystemslab/lind-wasm-dev # this might take a while ...\ndocker run --platform=linux/amd64 -it --privileged --ipc=host --init --cap-add=SYS_PTRACE securesystemslab/lind-wasm-dev /bin/bash\n</code></pre> <p>This container can be built locally and the following args can be varied at build time for use on any branch or configuration needed.</p> <p><pre><code>docker build \\\n  --platform=linux/amd64 \\\n  --build-arg USERNAME=lind \\\n  --build-arg BRANCH_NAME=main \\\n  --build-arg LLVM_VERSION=llvmorg-16.0.4 \\\n  --build-arg CLANG_PACKAGE=clang+llvm-16.0.4-x86_64-linux-gnu-ubuntu-22.04 \\\n  -f ./Docker/Dockerfile.dev \\\n  -t lind-dev .\n</code></pre> The build process can be quite long, depending on system resources on the build machine. You can then run it with:</p> <pre><code>docker run --platform=linux/amd64 -it --privileged --ipc=host --init --cap-add=SYS_PTRACE lind-dev /bin/bash\n</code></pre>"},{"location":"contribute/docker-release-workflow/","title":"Docker Hub Release Workflow","text":"<p>The workflow builds the lind-wasm Docker image from the release stage of <code>Dockerfile.e2e</code> and pushes it to Docker Hub as <code>securesystemslab/lind-wasm</code>. It is manual-only (<code>workflow_dispatch</code>), so contributors must trigger it on demand.</p>"},{"location":"contribute/docker-release-workflow/#1-prerequisites","title":"1. Prerequisites","text":"Requirement Purpose Write rights on this repo lets you add secrets &amp; trigger the workflow Docker Hub access-token (or password) for <code>securesystemslab</code> used by GitHub\u00a0Actions to authenticate the Docker\u00a0Hub image push <p>Use a token, not your password: In Docker Hub \u25b8 Account Settings \u2192 Security, create a Read/Write access token and rotate it regularly.</p>"},{"location":"contribute/docker-release-workflow/#2-add-the-docker-hub-secret","title":"2. Add the Docker Hub secret","text":"<ol> <li>GitHub repo \u25b8 Settings \u2192 Secrets and variables \u2192 Actions </li> <li>New repository secret    * Name: <code>DOCKERHUB_PASSWORD</code>    * Value: your access token </li> <li>Click Add secret</li> </ol> <p>The workflow references it as <code>secrets.DOCKERHUB_PASSWORD</code>. See GitHub\u2019s guide: Using secrets in GitHub Actions.</p>"},{"location":"contribute/docker-release-workflow/#3-run-the-workflow-manual-trigger","title":"3. Run the workflow (manual trigger)","text":"<ol> <li>Open the repo\u2019s Actions tab.  </li> <li>Select Build &amp; push lind-wasm image.  </li> <li>Click Run workflow, choose a branch (defaults to <code>main</code>), then Run.  </li> <li>Watch the logs: you should see build \u2192 login \u2192 push succeed.</li> </ol> <p>For details, check GitHub\u2019s Manually running a workflow guide.</p>"},{"location":"contribute/docker-release-workflow/#4-what-the-workflow-does","title":"4. What the workflow does","text":"<ol> <li>Checkout the repository code.  </li> <li>Build the Docker image from the release stage of <code>Dockerfile.e2e</code>.  </li> <li>Login to Docker Hub with <code>DOCKERHUB_PASSWORD</code>.  </li> <li>Tag &amp; push:    * <code>securesystemslab/lind-wasm:&lt;GIT_SHA&gt;</code> \u2013 every build    * <code>securesystemslab/lind-wasm:latest</code> \u2013 every build</li> </ol>"},{"location":"contribute/e2e-testing/","title":"End-to-End testing","text":"<p>Multi-stage .e2e flow for lind-wasm end-to-end testing and image creation.</p> <ul> <li>Installs build dependencies</li> <li>Builds wasmtime, glibc, and a sysroot for clang cross-compilation</li> <li>A. Runs end-to-end tests (default)</li> <li>B. Creates a Docker image with the lind-wasm toolchain</li> <li>C. Provides a base image for interactive development with the full source tree mounted</li> </ul> <p>NOTE The <code>test</code> stage (A) runs end-to-end tests on <code>docker build</code> and is optimized for build time and caching. It is not meant for <code>docker run</code>.  </p> <p>Use the <code>release</code> stage (B) to create an image that includes the full lind-wasm toolchain (for demos, experiments, etc.).  </p> <p>For development, you may want to build just the <code>base</code> stage (C) and mount the full source tree.</p> <p>The Dev image is automatically rebuilt weekly from <code>Docker/Dockerfile.dev</code> on <code>main</code> and pushed to Docker Hub as <code>securesystemslab/lind-wasm-dev:latest</code>.</p>"},{"location":"contribute/e2e-testing/#usage-a-test","title":"Usage A \u2014 test","text":""},{"location":"contribute/e2e-testing/#from-repo-root","title":"From repo root","text":"<p><code>docker build --platform=linux/amd64 -f Docker/Dockerfile.e2e .</code></p> <ul> <li> <p>Triggers the default test stage.</p> </li> <li> <p>Earlier stages build prerequisites (clang/LLVM, Rust, wasmtime, sysroot).</p> </li> <li> <p>The test stage executes make test during the build and fails the build on any test failure.</p> </li> <li> <p>Check the build log for the e2e report (the harness prints results.json).</p> </li> </ul>"},{"location":"contribute/e2e-testing/#usage-b-create-and-run-a-toolchain-image-release","title":"Usage B \u2014 create and run a toolchain image (release)","text":""},{"location":"contribute/e2e-testing/#build-a-runnable-toolchain-image","title":"Build a runnable toolchain image","text":"<p><code>docker build --platform=linux/amd64 -f Docker/Dockerfile.e2e -t release --target release .</code></p>"},{"location":"contribute/e2e-testing/#run-image","title":"Run image","text":"<p><code>docker run --platform=linux/amd64 -it release /bin/bash</code></p> <ul> <li> <p>Contains the lind-wasm toolchain (wasmtime + sysroot + scripts/tests).</p> </li> <li> <p>Intended for demos/experiments.</p> </li> <li> <p>Not designed to run make test directly (the Makefile isn\u2019t copied here).</p> </li> </ul>"},{"location":"contribute/e2e-testing/#usage-c-create-a-base-image-and-mount-the-source","title":"Usage C \u2014 create a base image and mount the source","text":"<p><code>docker build --platform=linux/amd64 -f Docker/Dockerfile.e2e -t dev --target base .</code></p> <p><code>docker run --platform=linux/amd64 -v $(PWD):/lind -w /lind -it dev /bin/bash</code></p> <ul> <li> <p>Use the <code>base</code> stage to match CI dependencies while keeping your source outside the image for fast, iterative editing.</p> </li> <li> <p>Inside the container, run <code>make build &amp;&amp; make test</code> to mirror CI exactly; the command exits non-zero on any e2e failure.</p> </li> </ul>"},{"location":"contribute/e2e-testing/#build-steps","title":"Build steps","text":""},{"location":"contribute/e2e-testing/#make-sysroot","title":"make sysroot","text":"<p>Runs <code>scripts/make_glibc_and_sysroot.sh</code> to:</p> <ul> <li> <p>Configure &amp; build glibc (WASM/WASI target) and compile additional NPTL/syscall bits and tiny ASM stubs.</p> </li> <li> <p>Collect selected <code>.o</code> objects (excluding objects defining <code>main</code>) and archive them into <code>src/glibc/sysroot/lib/wasm32-wasi/libc.a</code>; creates <code>libpthread.a</code>; installs headers under <code>src/glibc/sysroot/include/wasm32-wasi/</code>; and copies <code>crt1.o</code>.</p> </li> </ul>"},{"location":"contribute/e2e-testing/#make-wasmtime","title":"make wasmtime","text":"<ul> <li>Builds the embedded Wasmtime with Cargo (release) from <code>src/wasmtime/</code>.</li> </ul>"},{"location":"contribute/e2e-testing/#make-test","title":"make test","text":"<p>Runs <code>scripts/wasmtestreport.py</code> which:</p> <ul> <li> <p>Discovers tests from the repository\u2019s test trees and honors <code>skip_test_cases.txt</code>.</p> </li> <li> <p>Organizes results (e.g., deterministic / non_deterministic groups), writes <code>results.json</code> (and may render an HTML summary if enabled).</p> </li> <li> <p>The Makefile prints <code>results.json</code> and fails when any failures are present.</p> </li> </ul>"},{"location":"contribute/e2e-testing/#ci-overview-how-e2e-is-wired","title":"CI overview (how e2e is wired)","text":"<p>Workflow: <code>.github/workflows/e2e.yml</code></p> <p>High level:</p> <ul> <li> <p>Set up Docker Buildx for linux/amd64</p> </li> <li> <p>Build Docker/Dockerfile.e2e with GitHub Actions cache</p> </li> <li> <p>Execute the test stage (same behavior as Usage A)</p> </li> </ul>"},{"location":"contribute/e2e-testing/#caching","title":"Caching","text":""},{"location":"contribute/e2e-testing/#what-we-cache","title":"What we cache","text":"<ul> <li> <p>Buildx GHA layer cache (<code>cache-from/to: type=gha</code>) for apt/clang/rust/tooling and per-stage layers.</p> </li> <li> <p>Multi-stage outputs: <code>build-wasmtime</code> and <code>build-glibc</code> are mounted into <code>test</code>, so tests avoid rebuilding toolchains.</p> </li> </ul>"},{"location":"contribute/e2e-testing/#github-actions-semantics","title":"GitHub Actions semantics","text":"<ul> <li> <p><code>cache-from: type=gha</code> pulls layers from the hosted GitHub Actions cache.</p> </li> <li> <p><code>cache-to: type=gha,mode=max</code> pushes all reusable layers (not just the final image).</p> </li> <li> <p>The first cold run builds all layers; subsequent runs only rebuild changed layers, dramatically speeding up CI.</p> </li> </ul> <p>Note: GitHub Actions may evict cached layers over time; when that happens a run starts cold but still passes the same way.</p>"},{"location":"contribute/e2e-testing/#local-build-with-cache","title":"Local build with cache","text":""},{"location":"contribute/e2e-testing/#one-time-createselect-a-builder","title":"One-time: create/select a builder","text":"<p><code>docker buildx create --use --name lind-builder || docker buildx use lind-builder</code></p>"},{"location":"contribute/e2e-testing/#build-with-cache-importexport","title":"Build with cache import/export","text":"<p><code>docker buildx build --platform=linux/amd64 -f Docker/Dockerfile.e2e --cache-from type=local,src=~/.cache/docker-buildx --cache-to type=type=local,dest=.~/.cache/docker-buildx,mode=max .</code></p> <p>CI typically uses type=gha; locally a local cache is simple and reliable.</p>"},{"location":"contribute/e2e-testing/#troubleshooting","title":"Troubleshooting","text":"<ul> <li> <p>Apple Silicon / wrong arch \u2192 add --platform=linux/amd64 to all build/run commands.</p> </li> <li> <p>Slow first build \u2192 increase Docker memory (\u2248 6\u20138 GB) to accommodate sysroot/wasmtime builds.</p> </li> <li> <p>Stale artifacts \u2192 run make clean/make distclean and rebuild inside the dev (base) container.</p> </li> <li> <p>Cache debugging \u2192 add --progress=plain to docker build to see which step invalidated.</p> </li> </ul>"},{"location":"contribute/security/","title":"Security Issues and Bugs","text":"<p>Security issues can be reported to maintainers privately via GitHub:</p> <ul> <li>Report new vulnerability</li> </ul> <p>Please do not use the GitHub issue tracker to submit vulnerability reports. The issue tracker is intended for bug reports and to make feature requests.</p>"},{"location":"contribute/styleguide/","title":"Rust Style Guide","text":"<p>Rust code in <code>lind-wasm</code> follows the default Rust style and should be auto-formatted:</p> <pre><code>cargo fmt --all --manifest-path src/wasmtime/Cargo.toml\n</code></pre>"},{"location":"contribute/toolchain/","title":"Lind toolchain","text":"<p>The toolchain to build and run lind programs consists of the following components:</p> <ul> <li>Clang with WebAssembly System Interface (WASI) support to build glibc   and lind programs</li> <li>A custom glibc used as sysroot to build   lind programs</li> <li>A custom <code>wasm-opt</code> binary to enable multi-processing   in lind programs</li> <li>A custom WebAssembly runtime (<code>wasmtime</code>) with   RawPOSIX to run lind programs</li> <li>Cargo to build <code>wasmtime</code></li> </ul> <p>This document gives an overview of how the toolchain is built. The build process is automated with Docker, make and custom shell scripts. Please refer to the relevant files linked below for details about the build commands and used options.</p>"},{"location":"contribute/toolchain/#building-the-toolchain-step-by-step","title":"Building the toolchain step by step","text":"<ol> <li> <p>Install system dependencies (see <code>apt</code> in Dockerfile)</p> </li> <li> <p>Download Clang and install builtins (see \"Install clang\" in Dockerfile)</p> <p>Clang supports the WASI cross-compilation target out of the box, provided the necessary compiler runtime builtins and a matching sysroot. See wasi-sdk docs for details.</p> <p>A pre-built Clang can be downloaded from the llvm-project releases page. Matching builtins are available in the lind-wasm repo under <code>src/glibc/wasi</code>.</p> </li> <li> <p>Build glibc and generate sysroot (see <code>make sysroot</code>)</p> <ol> <li> <p>Configure and compile glibc for the WASI target with Clang</p> </li> <li> <p>Compile extra files:</p> <ul> <li><code>nptl/pthread_create.c</code></li> <li><code>lind_syscall/lind_syscall.c</code></li> <li><code>csu/wasm32/wasi_thread_start.s</code></li> <li><code>csu/wasm32/set_stack_pointer.s</code></li> </ul> </li> <li> <p>Generate sysroot</p> <p>Combine the built object files into a single archive file and copy along with headers and a pre-built C runtime into a sysroot directory structure as required by Clang.</p> </li> </ol> </li> <li> <p>Build custom wasmtime (see <code>make wasmtime</code>)</p> <p>Builds <code>src/wasmtime</code> workspace. Custom dependencies <code>fdtables</code>, <code>RawPOSIX</code>   and <code>sysdefs</code> are included in the build automatically.</p> </li> </ol> <p>A customized <code>wasm-opt</code> binary is included in the lind-wasm repo under <code>tools/binaryen/bin</code> and can be used as is.</p>"},{"location":"contribute/toolchain/#next-steps","title":"Next steps","text":"<p>Automate the build and run programs with <code>Docker</code> and <code>make</code>.</p>"},{"location":"contribute/unit-tests/","title":"Running unit tests","text":"<p>This document is a practical guide to setting up and using the Lind testing infrastructure. It outlines the steps needed to run the test suite, execute unit tests, and understand the results produced by the test suite, and how to contribute new tests to the framework.</p> <p>Since Lind is currently limited to the AMD64 architecture, Docker is used to provide a consistent and controlled testing environment across different host systems. You can install Docker from its website.</p>"},{"location":"contribute/unit-tests/#testing-workflow","title":"Testing Workflow","text":"<ol> <li>Clone the repo using  <pre><code>git clone https://github.com/Lind-Project/lind-wasm.git\n</code></pre></li> <li>Change directory to repo  <pre><code>cd lind-wasm\n</code></pre></li> <li>Build Docker Image  <pre><code>docker build --platform=linux/amd64 -f Docker/Dockerfile.e2e -t dev --target base .\n</code></pre></li> <li>Run the image  <pre><code># Note: The `-v` option mounts your repo into the container. This means, you can\n# live-edit the files in the container using your host editor. And files created\n# or edited in the container, e.g. when running `make`, persist on the host.\n\ndocker run --platform=linux/amd64 -v $(PWD):/lind -w /lind -it dev /bin/bash\n</code></pre></li> <li>Build toolchain (glibc and wasmtime) <pre><code># this may take a while ...\nmake wasmtime sysroot\n</code></pre></li> <li>Run the test suite  <pre><code>./scripts/wasmtestreport.py\n</code></pre> Run <code>scripts/wasmtestreport.py --help</code> to list available usage options.</li> </ol>"},{"location":"contribute/unit-tests/#what-test-suite-does","title":"What test suite does","text":"<ol> <li> <p>Test Case Collection: Scans <code>unit-tests</code> folder for <code>.c</code> files.</p> </li> <li> <p>Filtering: Applies include/exclude filters (<code>--run</code>, <code>--skip</code>, and    <code>skip_test_cases.txt</code>).</p> </li> <li>Test Execution: Compiles and executes each test case twice, with native    gcc and with lind-wasm, and records the output. (note: gcc is skipped for    tests with expected output fixture, and for tests with non-deterministic output)</li> <li>Comparing Outputs:  Marks test as successful, if outputs match    (note: non-deterministic tests always succeed, if compilation and execution    succeeds)</li> <li>Reporting: Test results are written to a JSON- and  an HTML-formatted    report in the current working directory. The reports include a summary of the    full test run, and status, error type, and output of each test case.</li> </ol>"},{"location":"contribute/unit-tests/#error-types","title":"Error Types","text":"<p>The output will show the total number of test cases, along with counts for successes, failures, and each of the following error types:</p> <ul> <li>\"Failure_native_compiling\": Failed during GCC compiling</li> <li>\"Failure_native_running\": Failed while running GCC compiled binary</li> <li>\"Native_Segmentation_Fault\": Segmentation Fault while running GCC binary</li> <li>\"Native_Timeout\": Timed Out during GCC run</li> <li>\"Lind_wasm_compiling\": Failed during compilation using lind-wasm</li> <li>\"Lind_wasm_runtime\": Failed while running lind-wasm compiled binary</li> <li>\"Lind_wasm_Segmentation_Fault\": Segmentation Fault while running wasm binary</li> <li>\"Lind_wasm_Timeout\": Timed out During Lind Wasm run</li> <li>\"Output_mismatch\": Mismatch in GCC and Wasm outputs</li> <li>\"Unknown_Failure\": Unknown Failure</li> </ul> <p>The outputs are split into deterministic and non-deterministic based on how the lind-wasm outputs are compared to the native gcc output. </p>"},{"location":"contribute/unit-tests/#directory-structure","title":"Directory Structure","text":"<ul> <li><code>tests/unit-tests/</code>: Folder containing all <code>.c</code> test cases.</li> <li><code>expected/</code>: Directory under each test folder for expected output files.</li> <li><code>testfiles/</code>: Extra files needed by tests, copied into Lind FS.</li> </ul>"},{"location":"contribute/unit-tests/#how-to-add-test-cases","title":"How to add test cases","text":"<p>To add test cases, a file with .c extension containing c code can be added to the appropriate folder in the tests/unit-tests folder.  During the test suite run, the test case will be picked up and run. If the outputs of the file can be directly compared, i.e. contents of gcc run == contents of lind-wasm run, that would be enough</p> <p>Any failure in compiling or running using gcc or lind-wasm is considered a failure. Mismatch in native (gcc) and wasm outputs are also considered a failure.</p>"},{"location":"contribute/unit-tests/#example-combined-usage","title":"Example Combined Usage","text":"<pre><code>./scripts/wasmtestreport.py \\\n  --generate-html \\\n  --skip config_tests file_tests \\\n  --timeout 10 \\\n  --output results_json \\\n  --report test_report  \n</code></pre> <p>This will:</p> <ul> <li>Skip specified folders</li> <li>Use a 10-second timeout</li> <li>Save output as <code>results_json.json</code></li> <li>Generate a report <code>test_report.html</code></li> </ul>"},{"location":"internal/","title":"Internal Documentation","text":"<p>This section contains internal implementation notes and references for core Lind-Wasm components (libc, Wasmtime integration, RawPOSIX, and subsystem topics).</p>"},{"location":"internal/libc/","title":"Modifications Made to glibc and <code>crt1.c</code>","text":""},{"location":"internal/libc/#1-changes-to-glibc","title":"1. Changes to glibc","text":""},{"location":"internal/libc/#11-changing-the-system-call-mechanism","title":"1.1 Changing the System Call Mechanism","text":"<p>The system call mechanism was modified to route system calls through <code>rawposix</code> instead of directly invoking the kernel. The new format for making system calls is structured as follows:</p> <pre><code>MAKE_SYSCALL(syscallnum, \"syscall|callname\", arg1, arg2, arg3, arg4, arg5, arg6)\n</code></pre> <p>For each system call file in glibc, a header file named <code>syscall-template.h</code> was added with the following content:</p> <pre><code>#include &lt;sys/syscall.h&gt;\n#include &lt;stdint.h&gt;    // For uint64_t\n#include &lt;unistd.h&gt;\n#include &lt;lind_syscall.h&gt;\n\n// Define NOTUSED for unused arguments\n#define NOTUSED 0xdeadbeefdeadbeefULL\n\n// Macro to create a syscall and redirect it to rawposix\n#define MAKE_SYSCALL(syscallnum, callname, arg1, arg2, arg3, arg4, arg5, arg6) \\\n    lind_syscall(syscallnum, \\\n                 (unsigned long long)(callname), \\\n                 (unsigned long long)(arg1), \\\n                 (unsigned long long)(arg2), \\\n                 (unsigned long long)(arg3), \\\n                 (unsigned long long)(arg4), \\\n                 (unsigned long long)(arg5), \\\n                 (unsigned long long)(arg6))\n</code></pre> <p>The <code>MAKE_SYSCALL</code> macro redirects system calls to rawposix, providing an interface for syscall handling in this context.</p>"},{"location":"internal/libc/#12-eliminating-assembly-code","title":"1.2 Eliminating Assembly Code","text":"<p>Since WebAssembly (WASM) does not support assembly, all assembly-related components in glibc were removed: - Inline assembly code was rewritten in C. - Files ending in <code>.s</code> were converted to <code>.c</code> files, and their functionalities were reimplemented in C.</p>"},{"location":"internal/libc/#13-handling-automatically-generated-s-files","title":"1.3 Handling Automatically Generated <code>.s</code> Files","text":"<p>glibc automatically generates <code>.s</code> files for certain system calls. To address this: - The script responsible for generating these <code>.s</code> files was disabled. - The corresponding system calls were manually implemented in C and placed in appropriate <code>.c</code> files.</p>"},{"location":"internal/libc/#14-additional-modifications","title":"1.4 Additional Modifications","text":"<ul> <li>Disable <code>_dl_mcount_wrapper_check</code>: This functionality was disabled as it is not required in the WASI environment.</li> <li>Change <code>initial-exec</code> to <code>local-exec</code>: All instances of <code>initial-exec</code> were replaced with <code>local-exec</code> to align with WebAssembly's threading and memory model.</li> <li>Implement <code>BYTE_COPY_FWD</code> and <code>BYTE_COPY_BWD</code>: These functions were implemented in C without relying on <code>memcpy</code> or <code>memmove</code> to ensure compatibility with the WASM environment.</li> <li>Disable <code>attribute_relro</code>: The original C code places the vtable into the <code>relro</code> section in the binary. Since WebAssembly binaries do not have this section, the attribute was disabled.</li> </ul>"},{"location":"internal/libc/#2-modifications-and-additions-to-crt1c-for-wasi","title":"2. Modifications and Additions to <code>crt1.c</code> for WASI","text":""},{"location":"internal/libc/#21-wasi-specific-function-wrappers","title":"2.1 WASI-Specific Function Wrappers","text":"<ul> <li>Wrappers for WASI Snapshot Preview 1 APIs:   Several wrappers were defined for handling WASI <code>args</code> and <code>environ</code> APIs, including:</li> <li><code>__imported_wasi_snapshot_preview1_args_sizes_get</code></li> <li><code>__imported_wasi_snapshot_preview1_args_get</code></li> <li><code>__imported_wasi_snapshot_preview1_environ_get</code></li> <li> <p><code>__imported_wasi_snapshot_preview1_environ_sizes_get</code></p> </li> <li> <p>Implementation:   These wrappers use the following attribute for integration:   <pre><code>__attribute__((\n    __import_module__(\"wasi_snapshot_preview1\"),\n    __import_name__(\"function_name\")\n));\n</code></pre></p> </li> <li> <p>Purpose: Enables access to WASI-specific argument and environment APIs.</p> </li> </ul>"},{"location":"internal/libc/#22-environment-initialization","title":"2.2 Environment Initialization","text":"<ul> <li>Added <code>__wasi_initialize_environ</code>:   This function initializes the environment variables by:</li> <li>Using <code>__wasi_environ_sizes_get</code> to determine the size of environment data.</li> <li> <p>Using <code>__wasi_environ_get</code> to populate the <code>environ</code> array.</p> </li> <li> <p>Fallback Logic:   If the environment is empty, the program:</p> </li> <li>Falls back to a static empty environment (<code>empty_environ</code>).</li> <li>Exits with an appropriate error code when necessary.</li> </ul>"},{"location":"internal/libc/#23-thread-and-tls-setup","title":"2.3 Thread and TLS Setup","text":"<ul> <li>Added Calls to <code>__libc_setup_tls</code> and <code>__wasi_init_tp</code>:   These functions are included in <code>_start</code> to set up thread-local storage (TLS) and thread pointers, which are essential for multithreading or TLS-dependent code.</li> </ul>"},{"location":"internal/libc/#24-main-function-handling","title":"2.4 Main Function Handling","text":"<ul> <li>Modified <code>__main_void</code> to Handle WASI Arguments:</li> <li>Initializes command-line arguments by:<ul> <li>Using <code>__wasi_args_sizes_get</code> to determine argument buffer sizes.</li> <li>Using <code>__wasi_args_get</code> to populate <code>argv</code> and <code>argv_buf</code>.</li> </ul> </li> <li> <p>Passes the initialized arguments to <code>__main_argc_argv</code>.</p> </li> <li> <p>Weak Symbol for <code>__main_argc_argv</code>:   Defined as a weak symbol to allow the dynamic linker to handle cases where no <code>main</code> function exists (e.g., in reactor-style applications).</p> </li> </ul>"},{"location":"internal/libc/#25-error-handling","title":"2.5 Error Handling","text":"<ul> <li>Specific Exit Codes:</li> <li> <p>Introduced <code>_Exit(EX_OSERR)</code> and <code>_Exit(EX_SOFTWARE)</code> for different error scenarios, aligning with <code>sysexits.h</code> standards.</p> </li> <li> <p>Purpose: Provides descriptive and standard error handling for memory allocation or initialization failures.</p> </li> </ul>"},{"location":"internal/libc/#26-placeholder-functions","title":"2.6 Placeholder Functions","text":"<ul> <li>Added Stub for <code>__wasm_call_dtors</code>:</li> <li> <p>An empty placeholder function for future destructor handling.</p> </li> <li> <p>Added Stub for <code>__wasi_proc_exit</code>:</p> </li> <li>A placeholder function for handling process exits in WASI.</li> </ul>"},{"location":"internal/libc/#27-memory-allocation-for-argv-and-environ","title":"2.7 Memory Allocation for <code>argv</code> and <code>environ</code>","text":"<ul> <li>Allocates memory dynamically for:</li> <li>Argument buffers (<code>argv_buf</code>) and pointers (<code>argv</code>).</li> <li>Environment buffers (<code>environ_buf</code>) and pointers (<code>environ_ptrs</code>).</li> <li>Uses <code>malloc</code> and <code>calloc</code> with robust error handling to prevent memory allocation failures.</li> </ul>"},{"location":"internal/memory/","title":"Memory Management and Vmmap","text":""},{"location":"internal/memory/#what-is-a-vmmap","title":"What is a Vmmap?","text":"<p>A vmmap is a tool for managing a process\u2019s memory layout within an operating system. It provides detailed insights into allocated memory regions, including the heap, stack, and memory-mapped files. Additionally, it displays access permissions (read-only, read-write, executable), memory region boundaries, sizes, and any mapped files.</p>"},{"location":"internal/memory/#motivation","title":"Motivation","text":"<p>Wasmtime traditionally manages memory using WebAssembly\u2019s linear memory model, where each instance gets a contiguous memory block divided into 64 KiB pages. This memory can grow or shrink dynamically within defined constraints. Since Lind emulates processes as cages within a single address space, tracking allocated memory regions per cage is essential.</p> <p>Attempts to provide POSIX-like interfaces for WASM, such as wasi-libc and emscripten, rely on WASM's memory.grow feature to expand available memory. Both implement custom malloc() functions that use memory.grow to extend the heap while preventing system mmap operations. Alternatively, they simulate file-backed mmap by invoking memory.grow and manually copying file contents into the allocated region.</p> <p>To address this, we eschew memory.grow and integrate a vmmap system into Lind that more closely resembles POSIX-based memory management. This allows proper implementation of syscalls like brk(), mmap(), and mprotect() for memory allocation, deallocation, and permission management. It also ensures accurate memory region copying when forking cages. Further justification for the need for a vmmap is provided in the later section \"Why the Vmmap is Necessary.\"</p>"},{"location":"internal/memory/#vmmap-implementation-overview","title":"Vmmap Implementation Overview","text":"<p>The vmmap internally uses a discrete interval tree to manage memory regions efficiently. This data structure functions similarly to a balanced tree, enabling fast lookups, insertions, and deletions of memory mappings. It supports optimized allocation by quickly identifying contiguous free memory blocks. Additionally, it ensures proper handling of updates, such as modifying protections or removing entries, by correctly managing overlapping regions through splitting or merging. Other key features include address range queries to validate memory access and enforce permissions, as well as functions for translating addresses between user space and system memory.</p> <p>Internal Operation Details: All vmmap operations use page numbers internally, not byte addresses, aligning with the underlying system memory model for efficient address space management. When operations modify only part of an existing memory entry, the system automatically creates new entries for unchanged portions while preserving their original attributes, ensuring fine-grained control over memory regions.</p>"},{"location":"internal/memory/#why-the-vmmap-is-necessary","title":"Why the Vmmap is Necessary","text":"<p>Without a vmmap, syscalls like mmap() and munmap() could still be implemented using a greedy approach with memory.grow, similar to how other systems simulate file-backed mmap, as described above. However, this method would be unsuitable for multi-processing and would violate POSIX compliance, as we explain in this section.</p>"},{"location":"internal/memory/#fork","title":"fork()","text":"<p>The fork() system call requires duplicating the parent process\u2019s memory space for the child. Properly replicating memory requires tracking protections and distinguishing shared memory regions. Memory regions possess distinct permissions\u2014either defined at creation or modified through mprotect(). Consequently, a simple bulk memory copy cannot accurately preserve these protections without tracking each region individually. Additionally, memory regions mapped with MAP_SHARED must be tracked individually to ensure proper sharing between cages. Without a mechanism like a vmmap, there is no way to distinguish shared regions from non-shared ones. By tracking shared regions, we can then use mremap when forking to create a shareable mapping between cages.</p>"},{"location":"internal/memory/#brk","title":"brk()","text":"<p>The brk() system call expands the heap linearly, ensuring contiguous allocation as required by libc and other libraries. Many functions, including malloc(), depend on this guarantee. Without a vmmap, memory allocation could use the aforementioned greedy approach, but this might interleave heap regions with other mappings created by mmap(), violating POSIX compliance and leading to library failures.</p>"},{"location":"internal/memory/#mmapmunmapmprotect","title":"mmap()/munmap()/mprotect()","text":"<p>It's necessary to manage memory allocated or modified using these calls to support the proper functiong of fork() and brk() as mentioned above.</p>"},{"location":"internal/memory/#additional-benefits","title":"Additional Benefits:","text":"<ul> <li>Reduced fragmentation: Without memory tracking, greedy allocation wastes space by failing to reuse deallocated pages. This is particularly crucial since cages are limited to 4GB of address space.</li> <li>Improved memory safety: Heap overflows are less likely to impact valid mappings, as heaps and other memory regions remain isolated unless explicitly mapped with MAP_FIXED.</li> </ul>"},{"location":"internal/memory/#system-calls","title":"System Calls","text":"<p>The implementation of mmap, brk, and sbrk interacts with vmmap, ensuring efficient allocation, deallocation, and permission enforcement for different types of memory regions.</p>"},{"location":"internal/memory/#mmap","title":"mmap()","text":"<p>mmap provides a mechanism for mapping memory regions with specific properties, such as anonymous memory for heap growth or file-backed mappings for shared memory. It allows fine-grained control over memory protection (PROT_READ, PROT_WRITE), allocation strategies (MAP_PRIVATE, MAP_SHARED), and address-space placement (MAP_FIXED). To ensure that memory mappings remain manageable, mmap works with vmmap to search for available memory regions. When vmmap searches for a free range, it always starts from the bottom of the address space and grows upwards. This minimizes fragmentation and avoids conflicts with the heap, which is placed at the top of memory and grows downwards.</p> <p>How It Works</p> <ol> <li>Memory Region Identification:<ul> <li>If MAP_FIXED is not set, vmmap searches for a suitable free memory region in strict mode, rejecting any overlapping entries.</li> <li>If MAP_FIXED is specified, the requested address is used directly and may result in overwriting existing entries.</li> </ul> </li> <li>Memory Protection and Flags Enforcement:<ul> <li>Only a restricted set of flags are allowed to prevent unintended behavior.</li> <li>Execution permissions (PROT_EXEC) are explicitly disallowed for security reasons.</li> </ul> </li> <li>Address Translation and System Invocation:<ul> <li>The selected virtual address is translated into a system address. -The actual mmap operation is invoked on the host system with MAP_FIXED to ensure deterministic placement.</li> </ul> </li> <li>Updating the vmmap:<ul> <li>If the mapping is successful, vmmap is updated to reflect the allocated region, including its permissions and backing type (anonymous or file-backed).</li> <li>When new entries overlap with existing ones, they replace overlapping entries rather than merging them. New entry attributes completely override old attributes in the overlapping region, with automatic splitting for partial overlaps.</li> </ul> </li> </ol>"},{"location":"internal/memory/#munmap","title":"munmap()","text":"<p>munmap is used to release memory mappings previously allocated via mmap. Unlike traditional implementations that return memory to the OS, Lind\u2019s munmap only marks the region as inaccessible by setting it to PROT_NONE, while retaining it within the process's address space.</p> <p>How It Works</p> <ol> <li>Address Validation:<ul> <li>The target address must be aligned to page boundaries.</li> <li>The region must exist within vmmap and must not contain protected memory.</li> </ul> </li> <li>Memory Protection Adjustment:<ul> <li>Instead of actually deallocating memory, the affected region is marked as PROT_NONE. The memory remains allocated but becomes inaccessible.</li> </ul> </li> <li>Updating vmmap:<ul> <li>The mapping entry is removed from vmmap, ensuring that the region is available for future allocations.</li> </ul> </li> </ol>"},{"location":"internal/memory/#mprotect","title":"mprotect()","text":"<p>mprotect() allows modification of protection flags for existing memory mappings, enabling or disabling read, write, and execute permissions for specified regions.</p> <p>How It Works</p> <ol> <li>Protection Change:<ul> <li>Only the requested protection field is modified; all other entry metadata remains unchanged, including <code>maxprot</code>, backing type, flags, and other attributes.</li> </ul> </li> <li>Address Alignment:<ul> <li>The target address and length must be page-aligned.</li> <li>The region must correspond to an existing memory mapping in vmmap.</li> </ul> </li> <li>Updating vmmap:<ul> <li>The protection attributes of the affected vmmap entry are updated without affecting other region properties.</li> </ul> </li> </ol>"},{"location":"internal/memory/#brksbrk","title":"brk()/sbrk()","text":"<p>brk and sbrk provide a mechanism to dynamically expand or shrink the heap by adjusting the program break. This is essential for memory allocation routines such as malloc, which rely on contiguous heap growth. In Lind, the heap is always placed at the top of the memory space, right after the stack region, and grows downwards. This is opposite to the direction in which mmap allocates memory (bottom-up), ensuring that mmap-allocated regions do not typically interfere with heap growth.</p> <p>How It Works</p> <ol> <li>Tracking the Program Break:<ul> <li>The program break corresponds to the end of the heap region in vmmap.</li> <li>sbrk(0) returns the current break, while sbrk(N) attempts to increase the heap by N bytes.</li> </ul> </li> <li>Heap Expansion:<ul> <li>When increasing the program break, the system first verifies that the requested range does not overlap with existing mappings.</li> <li>If space is available, the permissions of the new memory region are updated to match the heap\u2019s permissions.</li> <li>The vmmap entry is updated to reflect the new program break.</li> </ul> </li> <li>Heap Shrinking:<ul> <li>If the program break is decreased, memory beyond the new limit is marked as inaccessible (PROT_NONE) instead of being deallocated immediately, similar to munmap.</li> <li>The vmmap entry is updated accordingly.</li> </ul> </li> </ol>"},{"location":"internal/multiprocess-support/","title":"Multi-Process Support in Lind-Wasm","text":""},{"location":"internal/multiprocess-support/#multi-processing-via-asyncify","title":"Multi-processing via Asyncify","text":"<p>The way multi-process (specifically clone_syscall, exit_syscall and longjmp) works in lind-wasm heavily depends on Asyncify from Binaryen. So let\u2019s first introduce how Asyncify works on WebAssembly.\\ So Asyncify is a second-time compilation that adds some logic to the existing compiled file.\\ The Asyncify works by having a few global variables that define the current execution status. One global variable is to describe the current status of stack unwind/rewind. If current_state is set to unwind, that means the current process is undergoing stack unwind, and if current_state is set to rewind, that means the current process is undergoing stack rewind, and if current_state is set to normal, that means the current process is working normally, just like no Asyncify has applied to it.\\ \\ For example, suppose there is a program looks like this:</p> <pre><code>int funcA()\n{\n    int a;\n    int b;\n\n    for... {\n        ...do some work...\n    }\n\n    funcB();\n\n    ...do some work...\n}\n\nint funcB()\n{\n    ...do some work\n      imported_wasm_functionC();\n}\n</code></pre> <p>After applying Asyncify, it may become something like this:</p> <pre><code>int funcA()\n{\n    if(current_state == rewind) {\n        restore_functionA_context();\n    }\n    if(current_state == normal) {\n        int a;\n        int b;\n\n        for... {\n            ...do some work...\n        }\n    }\n    if(last_unwind_return_is_here)\n    {\n        funcB();\n        if(current_state == unwind) {\n            save_functionA_context();\n            return;\n        }\n    }\n\n    if(current_state == normal) {\n        ...do some work...\n    }\n}\n\nint funcB()\n{\n    if(current_state == rewind) {\n        restore_functionB_context();\n    }\n    if(current_state == normal) {\n        if(current_state == normal) {\n            ...do some work\n        }\n    }\n\n    if(last_unwind_return_is_here) {\n        imported_wasm_functionC();\n        if(current_state == unwind) {\n            save_functionB_context();\n            return;\n        }\n    }\n}\n</code></pre> <p>So Asyncify basically adds an if statement for all the normal user code and only executes the user code if current_state is normal. After a function has been executed, it will check if current_state is set to unwind. If that is the case, the function context will be saved and the function will return immediately. When rewind happens later, the function context will be restored at the beginning of the function.\\ \\ Besides these, Asyncify also has four functions that control the global current_state.\\ Asyncify_unwind_start: Once called, set current_state to unwind and return\\ Asyncify_unwind_stop: Once called, set current_state to normal and return\\ Asyncify_rewind_start: Once called, set current_state to rewind and return\\ Asyncify_rewind_stop: Once called, set current_state to normal and return\\ Asyncify_unwind_start and Asyncify_rewind_start also takes an additional argument that specifies where to store/retrieve the unwind_data (i.e. function context).</p> <p>Such transformation from Asyncify allows you to freely navigate the callstack of a process, but with the cost of largely increased binary size, and slightly decreased performance (from a bunch of extra if statements added by Asyncify).</p>"},{"location":"internal/multiprocess-support/#fork","title":"fork()","text":"<p>The fork syscall is built up on Asyncify. When fork is called, the whole wasm process would undergo unwind and rewind. But the unwind_data (function context) is copied once unwind is done. The unwind_data could basically be viewed as a snapshot of the callstack (with the unwind_data, we can restore the wasm process to the state when unwind_data is captured). With such a powerful mechanism, the implementation of the fork is pretty straightforward: once we capture the snapshot of the parent process callstack, we can let the child do the rewind with the unwind_data from parent, and the child will be able to return to the exact state when parent calls fork. Threading creation is very similar to this, except that the memory is shared between parent and child.</p>"},{"location":"internal/multiprocess-support/#exit-and-exec","title":"exit() and exec()","text":"<p>Exit syscall is currently also built on Asyncify, by performing the unwind on the process, then instead of doing rewinding, the process can just return.</p> <p>Exec syscall is built upon Exit syscall: instead of returning directly after unwind is finished, a new wasm instance is created with the supplied binary path.</p>"},{"location":"internal/multiprocess-support/#setjmp-and-longjmp","title":"setjmp() and longjmp()","text":"<p>Setjmp and longjmp implementation is also very similar to fork: When setjmp is called, the process will undergo unwind and rewind, leaving an unwind_data (callstack snapshot). The unwind_data is saved somewhere. When later the process calls longjmp and specifies a restore to the previous state, the process first will unwind, after unwind is finished, its unwind_data will be replaced by the old unwind_data generated when setjmp is called. Then after rewind, the process can restore to its previous state. </p>"},{"location":"internal/multiprocess-support/#wait","title":"wait()","text":"<p>Last we have our wait_syscall which is implemented purely in rawposix and does not use Asyncify at all. Wait_syscall works by maintaining a zombie relationship in the cage struct: when a cage exits, it will insert itself into the parent\u2019s zombie list. Therefore, the parent can simply check its zombie list when doing the wait syscall, and retrieve the first zombie in the list (first in first out).</p>"},{"location":"internal/rawposix/","title":"Introduction","text":""},{"location":"internal/rawposix/#overview-of-rawposix","title":"Overview of RawPOSIX","text":"<p>RawPOSIX is a critical component of the Lind Project, designed to provide a POSIX-compliant interface for applications running within a microvisor environment. The primary goal of RawPOSIX is to enable the execution of both legacy and modern multi-processes\u2019 applications safely and efficiently within the same address space without any modification to source code and perform the same behavior with applications running on native Linux.</p>"},{"location":"internal/rawposix/#purpose-and-scope-of-rawposix","title":"Purpose and Scope of RawPOSIX","text":"<p>The purpose of the RawPOSIX project is to provide an in-process OS while isolating them. By offering a POSIX-like interface, RawPOSIX is an interface implemented on top of standard POSIX (Linux) system calls. It provides functionalities such as signals, fork/exec, threading, file system operations, and networking. Additionally, RawPOSIX manages file descriptors (FDs), threads, and other resources independently for each cage, ensuring proper isolation and resource handling. This is particularly beneficial for legacy applications that rely on POSIX standards.</p> <p>The scope of RawPOSIX encompasses several key areas: - System Call API: Implementing a set of raw POSIX system calls that redirect low level operations to kernel and a set of userspace system calls based on POSIX standard to cover process management, network operations, and memory management. - Cage Structure: A \"cage\" data structure in RawPOSIX is designed to handle per-process information while providing required memory management. - Testing and Validation: Providing a testing framework to ensure the reliability and correctness of the RawPOSIX implementation.</p>"},{"location":"internal/rawposix/#key-components-and-files","title":"Key Components and Files","text":"<p>The RawPOSIX repository is organized into several important folders and files that contribute to its functionality: - src/: This directory contains the main Rust codebase for RawPOSIX. It includes the implementation of the syscall API and other core components. - syscalls.rs: This file defines the various system calls supported by RawPOSIX, implementing the logic for each operation. - cage.rs: This file contains definitions of the Cage data structure as well as functions of corresponding operations like creation / insertion / etc. and life cycle management of cages. - tests/: This directory includes test cases and scripts to validate the functionality of RawPOSIX. It ensures that all system calls and cage operations work as expected. - docs/: Documentation files that provide additional context and instructions for setting up and using RawPOSIX.</p>"},{"location":"internal/rawposix/#syscall-api","title":"Syscall API","text":""},{"location":"internal/rawposix/#supported-system-calls","title":"Supported System Calls","text":"<p>In RawPOSIX, raw syscalls are used for direct interactions with the Linux kernel to handle low-level operations, while userspace syscalls serve as abstractions tailored to manage runtime-specific needs (e.g., WASM or Native Client) and ensure isolation through features like per-cage memory management and multi-processing support.</p> <p>For standard system calls, RawPOSIX primarily processes variables passed from the runtime environment and redirects them to the Linux kernel. Beyond supporting standard POSIX system calls (e.g., file system and networking calls), RawPOSIX implements additional features, including: - Memory Management: RawPOSIX provides memory management tailored to the runtime environment, leveraging VMMap-related system calls to enable per-cage memory management. - Process Management: Functions such as wait, waitpid, fork, exec, and signal handling are implemented to support multi-processing. These functions update the cage structure and corresponding data structures as needed, ensuring proper isolation and accurately reflecting the state of processes.</p>"},{"location":"internal/rawposix/#testing","title":"Testing","text":"<p>RawPOSIX employs a comprehensive testing framework to validate its functionality and ensure that all components operate as expected. The testing framework is designed to cover scenarios including both normal usage and error returns. Tests can be found on: lind-wasm/src/RawPOSIX/src/tests/</p>"},{"location":"internal/signals/","title":"Signal Implementation Design Documentation","text":""},{"location":"internal/signals/#1-binary-rewriting","title":"1. Binary Rewriting","text":"<p>As we do not have a way to interrupt a running WebAssembly thread without directly using kernel functions like <code>pthread_kill</code>, our approach inserts signal checks into the Wasm binary. These checks allow the binary to spontaneously callback to the host when the host indicates there are pending signals via an epoch mechanism. The inserted signal checks detect changes in the epoch value, which is managed by Wasmtime\u2019s existing epoch insertion infrastructure at the Cranelift IR level.</p> <p>However, this approach is incompatible with Asyncify, the tool we use to support multi-processing, as Asyncify operates at the Wasm level. To have both epoch-based signal handling and Asyncify-based multi-processing work together, we had two options:</p> <ul> <li>Modifying Wasmtime\u2019s IR-level epoch insertion to make it compatible with Asyncify.</li> <li>Implementing our own Wasm-level epoch insertion.</li> </ul> <p>We chose the latter, as implementing our own Wasm-level epoch insertion is simpler and ensures compatibility with Asyncify automatically.</p>"},{"location":"internal/signals/#2-epoch-management","title":"2. Epoch Management","text":"<p>Epoch management must be carefully handled to ensure correct signal delivery and processing. The epoch can be in one of three states:</p> <ul> <li><code>Normal</code> state: No pending signals.</li> <li><code>Signal</code> state: A pending signal needs to be handled.</li> <li><code>Kill</code> state: The thread needs to be terminated.</li> </ul> <p>When the epoch transitions to either the <code>signal</code> state or the <code>kill</code> state, execution jumps to a callback function in the host. The host then determines the appropriate action based on the signal type. For example, a <code>SIGKILL</code> will immediately terminate the process, whereas other signals may invoke custom guest-defined handlers.</p> <p>During the execution of a signal handler, the epoch must be reset to the <code>normal</code> state to prevent unintended interruptions inside the handler. However, this reset only occurs when there are no more unblocked pending signals. In other words, additional pending signals will continue to interrupt the current signal handler until all the signals are handled.</p> <p>Whenever a new signal is delivered, the following occurs:</p> <ol> <li>If the signal is not blocked, the epoch state is immediately set to the <code>signal</code> state, ensuring the signal is processed promptly.</li> <li>When the epoch is triggered, the host retrieves the first unblocked signal from the pending list and invokes the corresponding signal handler.</li> <li>The epoch state remains in the <code>signal</code> state until all pending (unblocked) signals are processed.</li> <li>New signals received during handler execution are appended to the pending list and will be processed before earlier signals, mirroring Linux\u2019s behavior.</li> </ol> <p>In case of a new signal delivered during the execution of the signal handler, we do not need to take any special consideration. It will be appended to the pending signal list normally and switch epoch to the <code>signal</code> state. This will always make the latest signal being handled first, similar to Linux\u2019s behavior.</p>"},{"location":"internal/signals/#3-epoch-based-signal-handling-with-asyncify","title":"3. Epoch-Based Signal Handling with Asyncify","text":"<p>One key challenge in integrating epoch-based signal handling with Asyncify is ensuring compatibility, particularly when the system is in rewind state. If a signal handler interacts with Asyncify, the entire call stack\u2014including the epoch callback function within the host\u2014must be compatible with Asyncify\u2019s transformation logic.</p> <p>To achieve this, we manually apply Asyncify transformation to our host epoch callback function. Since we support recursive signal handling, we must maintain a record of:</p> <ul> <li>The order of executed signal handlers within the call stack.</li> <li>The parameters passed to each handler.</li> </ul> <p>If a signal handler returns due to an Asyncify unwind operation, we must detect this condition and immediately break the loop processing pending signals, returning control to the unwinding call stack.</p> <p>If the epoch callback function is reached while in Asyncify rewind state, we must detect the rewind state and skip the normal epoch handling logic, resuming the call stack by directly invoking the last active signal handler with its remembered parameters.</p>"},{"location":"internal/signals/#4-sigaction-and-sigprocmask","title":"4. <code>sigaction</code> and <code>sigprocmask</code>","text":"<p>The <code>sigaction</code> and <code>sigprocmask</code> syscalls do not need to directly interact with the epoch mechanism. Instead, they can be safely stored in the process\u2019s cage structure until needed by other syscalls. The <code>sigprocmask</code> information is checked when processing pending signals to determine whether a signal should be skipped due to being blocked.</p> <p>A notable aspect of <code>sigprocmask</code> handling is managing signals that are unblocked. If a signal is unblocked while it is still pending, the epoch state should immediately transition to the <code>signal</code> state, similar to when a new signal is received.</p> <p>When a signal handler is executed, we must temporarily block signals specified in the <code>sa_mask</code> field of <code>sigaction</code>. Once the signal handler finishes execution, we restore the signal mask to its previous state, overriding any modifications made during the execution of the signal handler. This behavior is consistent with Linux, which forcibly restores the signal mask after a handler completes\u2014even if <code>sigprocmask</code> was modified inside the handler.</p> <p>By default, the same signal will be blocked during its execution of its handler. Therefore, we explicitly add the same signal to <code>sa_mask</code>, preventing the handler from being re-entered while it is executing. To support <code>SA_NODEFER</code>, we can simply unset the same signal in the mask.</p> <p>We also support <code>SA_RESETHAND</code> by resetting the signal handler to its default state once the signal is handled, ensuring the handler is executed only once.</p>"},{"location":"internal/signals/#5-threads-termination","title":"5. Threads Termination","text":"<p>We introduced the <code>kill</code> state in the epoch mechanism primarily to enable terminating all running threads within a cage when necessary. The <code>kill</code> state uses the same host callback function as the <code>signal</code> state, but it is explicitly checked at the beginning of the callback function to perform a suicide operation if required.</p> <p>To support this, we need to store the epoch handler for each thread in the cage to be able to update the epoch state for all threads simultaneously.</p> <p>The suicide operation is implemented using Wasmtime\u2019s internal trap mechanism. By raising a special trap within the thread, Wasmtime can intercept and distinguish it from regular traps caused by faults such as segmentation faults. If the trap originates from the epoch mechanism, it is ignored, and the WebAssembly instance exits cleanly as if it terminated normally.</p> <p>Thread termination is essential for handling signals like <code>SIGKILL</code> correctly, as <code>SIGKILL</code> must terminate all threads in a process.</p>"},{"location":"internal/signals/#6-main-thread-management","title":"6. Main Thread Management","text":"<p>Since per-thread signals are not currently supported, signal-related structures such as the <code>sigaction</code> state and signal mask state are shared among all threads within a cage. When a signal is delivered, one thread must handle it while the others continue running normally. To achieve this, we designate a main thread responsible for processing all signals.</p> <p>By default, the main thread is the first thread spawned in the cage. However, if the main thread exits while other threads are still running, a new main thread must be selected. In this case, we can simply choose a random running thread as the new main thread.</p>"},{"location":"internal/signals/#todos","title":"TODOs","text":"<ul> <li>Use the new epoch-based method for implementing the exit syscall: Since we already have the infrastructure to terminate all threads within a cage, this mechanism should be applicable for handling the exit syscall. However, a minor issue remains regarding how to properly propagate the exit code upstream, which has not yet been implemented in the existing codebase.</li> <li>Add an epoch check in the host immediately after a syscall completes and before returning to the guest: Linux performs a signal check before transitioning from kernel mode to user mode, and we can adopt a similar approach to align our implementation more closely with Linux. One challenge is ensuring compatibility with Asyncify in the syscall path, as introducing another function in the call stack requires careful manual Asyncify transformation.</li> <li>Support for <code>SIGSTOP</code> and <code>SIGCONT</code>: We intend to support <code>SIGSTOP</code> and <code>SIGCONT</code>, which can be implemented by making the WebAssembly thread sleep and wake up accordingly. This should be straightforward.</li> <li>Enable signal interruption during syscalls: To support signal handling during blocking syscalls, we can modify all blocking syscalls to use a timeout-based version that periodically checks for signals. Additionally, the <code>SA_RESTART</code> flag could be a useful feature to implement in the future.</li> </ul>"},{"location":"internal/wasmtime/","title":"Introduction to Wasmtime","text":""},{"location":"internal/wasmtime/#what-is-wasmtime","title":"What is Wasmtime?","text":"<p>Wasmtime is a standalone JIT-style runtime for WebAssembly, designed for use with WebAssembly System Interface (WASI) and other WASI-inspired environments. It is part of the Bytecode Alliance, an open-source effort to create secure software foundations.</p> <p>Wasmtime can run WebAssembly modules that follow the WASI standard, providing a robust and efficient environment for running WebAssembly outside of the browser.</p>"},{"location":"internal/wasmtime/#getting-started-with-wasmtime","title":"Getting Started with Wasmtime","text":"<p>To get started with Wasmtime, you can download and install it from the official Wasmtime releases page. Follow the installation instructions specific to your operating system.</p>"}]}