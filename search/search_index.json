{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Lind-Wasm","text":"<p>Lind is a sandbox that isolates different applications in the same address space. Thus, conceptually, it executes different applications (which traditionally would be different processes) in separate, non-overlapping parts of a single address space, under a single, non-privileged Linux process.   To provide memory safety, control flow integrity, memory isolation, and similar properties, this version of Lind executes applications using WebAssembly for software fault isolation.  Lind also contains a custom kernel microvisor, written in Rust, which performs strict type checking and safe type conversion (e.g., between 32-bit and 64-bit representations), and enforces resource management and file-system isolation, thereby limiting the potential damage caused by bugs or security flaws in an application.</p> <p>In Old Norse, Old High German and Old English a \"lind\" is a shield constructed with two layers of linden wood. Linden wood shields are lightweight, and do not split easily, an appropriate metaphor for a sandboxing system which is lightweight and which provides layered security.</p>"},{"location":"#technology-overview","title":"Technology Overview","text":""},{"location":"#cages","title":"Cages","text":"<p>A cage runs a Linux application in an isolated part of the Lind process's namespace.  The code must recompiled to run in Wasm and linked to our modified glibc so that it makes its system calls through 3i.  However, the source code for applications only needs to be modified in rare cases (such as applications that directly make system calls).</p>"},{"location":"#grates","title":"Grates","text":"<p>A key advantage of 3i is the ability to support interposition.  In other words, a cage can intercept the system calls from another cage.  Because the use case of writing a cage to intercept system calls is very lightweight it is common in Lind.  As such, we give these cages the special name \"grate\".  This is meant to convey the mental picture of a caged application which calls down through a series of grates before (potentially) reaching the operating system.</p> <p>Note that a grate is a cage and Lind makes no actual distinction between them.  Any cage can make the system calls available to grates (unless a grate below it prevents it).  It is just that most legacy applications do not need to regularly make such calls.  This is analogous to strace and its use of the ptrace mechanism.</p> <p>A major advantage is that this means that implementing something like an in-memory file system can now be done without changing the microvisor or other trusted code.  A grate can intercept the file system calls and code written in C, Rust, etc. can be used to provide this functionality.  Similarly, a network file system can be implemented in a grate by the grate making whatever network system calls are needed.  </p> <p>Another important feature of grates is that they are composable.  A grate may itself have another grate beneath it which provides a separate service.  The recommended grate creation philosophy of 3i is similar to the philosophy in Unix of having small, composable commands you combine with pipes and similar functionality.  So, grates tend to be smaller, simpler utilities that can be combined.  This is sensible since the overhead of having separate cages and calling between cages is very low.</p> <p>Another similarity of Unix pipelines has to do with how grates interact.  The overwhelmingly common use case for pipes in Unix is to chain commands together sequentially so that the stdout of one becomes the stdin of the next.  However, the pipe functionality is itself general and supports many different use cases beyond this.  The interposition mechanism in 3i is similar in that most grates are likely to be stacked and simply provide functionality to whatever is above them.  However, since the system call table is per-cage and is truly programmable, a sufficiently privileged (ancestor) grate could rewire system calls for all of its descendents in any manner desired.</p> <p>In addition to intercepting system calls, a grate can also perform system calls on behalf of a descendant cage.  This is useful in situations where a cage should perform an operation like exiting or setting up a memory mapping or similar, where the goal is for the system to act as though the cage is making the call instead of the grate.</p> <p>When performing system calls, it is often useful for a grate to be able to pass arguments that refer to buffers in other cages (e.g., the buffer used in a write call).  Thus 3i system call arguments support a notion of which cage each argument comes from.</p> <p>Inheritance Properties:</p> <ul> <li>A child inherits system call handlers from its parent on fork. Thus, if cage A was forked by cage B, cage A will have the same system call handlers as cage B</li> <li>An ancestor can change the system call table for its decendents and perform calls on their behalf.</li> </ul>"},{"location":"#core-concepts","title":"Core Concepts","text":"<ul> <li>Cage: This term describes the isolated memory namespace that an application executes in.  It is analogous to a process in Linux. <ul> <li>Can run legacy code compiled with Wasm as a target</li> <li>Protects and isolates memory, control flow, etc.</li> </ul> </li> <li>Microvisor: RawPOSIX is a small kernel analogous to Linux running within the unprivileged Lind process. This is analogous to the Linux kernel.  Note, however, that this and all of the rest of Lind runs as an unprivileged Linux process.<ul> <li>Provides a POSIX-like interface (runs most Linux programs)</li> <li>Handles file descriptor separation, fork, exec, signals, threading, etc.</li> </ul> </li> <li>3i (pronounced \"three-I\"): Capability-based POSIX interface to call between cages or into the microvisor.  This is conceptually similar to a programmable system call table and IPC interface. <ul> <li>Each cage has a separate system call table which can be independently changed to redirect into other cages or the microvisor</li> <li>Fast, isolated calling between cages</li> <li>Enables complex functionality (system call filtering, file systems, proxies, etc.) to be external to the microvisor</li> </ul> </li> </ul>"},{"location":"#components","title":"Components","text":""},{"location":"#wasmtime-our-caging-technology","title":"Wasmtime (our caging technology)","text":"<p>Wasmtime is a fast and secure runtime for WebAssembly designed by the Bytecode Alliance. Lind-wasm uses wasmtime as a runtime with added support for multi-processing via Asyncify.</p>"},{"location":"#lind-glibc","title":"lind-glibc","text":"<p>We\u2019ve ported glibc so that it can be compiled to wasm bytecode and linked with any wasm binary. This includes minor changes like replacing assembly code, and add a mechansim to transfer system calls to the trusted runtime and microvisor.  Also, all system calls are converted to 64-bit system call types because all grates (and the underlying RawPOSIX implementation) support 64-bit system calls.</p>"},{"location":"#rawposix-our-microvisor-technology","title":"RawPOSIX (our microvisor technology)","text":"<p>Provides normal POSIX system calls including:</p> <ul> <li>Signals</li> <li>Fork</li> <li>Exec</li> <li>Threading</li> <li>File system</li> <li>Networking</li> <li>Separate handling of cages' fds and threads</li> </ul>"},{"location":"#3i-implementation","title":"3i Implementation","text":"<p>The intra-process interposable interface (3i) enables secure and efficient cage communication with speed similar to a function call. It provides POSIX interfaces between cages with interposition capabilities, enabling fine-grained security and access control by supporting the construction of grates.</p>"},{"location":"#frequent-qa","title":"Frequent Q&amp;A","text":""},{"location":"#how-hard-is-it-to-use-lind-wasm","title":"How hard is it to use Lind-Wasm?","text":"<p>Lind-Wasm aims to minimize application changes. Most applications can run without source-level modifications and only need to be recompiled using <code>clang</code> with Lind-Wasm\u2013related feature flags.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<ol> <li>Make sure to read the Basics first.</li> <li>If you want to start contributing, check out the Contributor Instructions.</li> <li>Continue reading to run a Hello World program in the Lind Sandbox.</li> </ol>"},{"location":"getting-started/#hello-world","title":"Hello World!","text":"<p>1. Set up the environment</p> <p>Run the following commands in your terminal to download and shell into an environment that comes with the Lind Sandbox. You'll need Docker installed.</p> <pre><code>docker pull --platform=linux/amd64 securesystemslab/lind-wasm-dev  # this might take a while ...\ndocker run --platform=linux/amd64 -it securesystemslab/lind-wasm-dev /bin/bash\n</code></pre> <p>This is a development environment with tooling and source code available, additional instructions to be found here</p> <p>2. Write a program</p> <p>In the same terminal, use e.g. <code>vi</code> to write a <code>hello.c</code> program to be executed in the Lind sandbox. You can also just paste the snippet below.</p> <pre><code>cat &lt;&lt; EOF &gt; hello.c\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"Hello, World!\\n\");\n    return 0;\n}\nEOF\n</code></pre> <p>3. Compile Lind-Wasm Runtime</p> <p>Lind-wasm runtime must be compiled before running the program. To compile the lind-wasm runtime, you will first go to the <code>lind-wasm/</code> directory. At there, you can choose:</p> <p>3.a. use <code>make all</code> to compile both lind-glibc and rust code at once.</p> <p>3.b. use <code>make lind-boot</code> to compile runtime(lind-boot/wasmtime/rawposix/3i/etc.), and <code>make sysroot</code> to compile lind-glibc.</p> <p>NOTES: More options can be found in lind-wasm/Makefile</p> <p>3. Compile and run</p> <p>Use lind scripts to compile and run your program in the Lind Sandbox.</p> <pre><code>lind-clang hello.c\nlind-wasm hello.cwasm\n</code></pre> <p>Here is what happens under the hood:</p> <ol> <li><code>lind-clang</code>(aka <code>scripts/lind_compile</code>) compiles <code>hello.c</code> into a WebAssembly (WASM) binary that is linked against lind-glibc, and put into lind file system root(<code>lind-wasm/lindfs</code>).</li> <li><code>lind-wasm</code>(aka <code>scripts/lind_run</code>) runs the compiled wasm using lind-wasm runtime and the lind-posix microvisor.</li> </ol> <p>To compile a Rust crate into a lind-glibc linked WASM binary, follow this guide: Compiling Rust Code with <code>lind-glibc</code></p>"},{"location":"getting-started/#whats-next","title":"What's next!","text":"<p>The Lind documentation is currently under heavy construction. Please submit an issue, if something doesn't seem right or is missing. More detailed usage guides will follow soon!</p>"},{"location":"community/","title":"Community","text":"<p>Join #lind on the NYU Secure Systems Lab Slack to receive updates about the project and upcoming events, or dial in on a community meeting! Details are listed below and on Google Calendar.</p>"},{"location":"community/#meetings","title":"Meetings","text":""},{"location":"community/#governance-committee","title":"Governance Committee","text":"<ul> <li>Weekly on Friday 15:00 - 16:00 ET</li> <li>Zoom</li> <li>Meeting notes</li> </ul>"},{"location":"community/#tech-talks","title":"Tech Talks","text":"<ul> <li>Every 2 weeks on Friday 13:00 - 14:00 ET</li> <li>Zoom</li> <li>Meeting notes</li> </ul>"},{"location":"community/#maintainers-evaluation-benchmarking-wg","title":"Maintainers, Evaluation, &amp; Benchmarking WG","text":"<ul> <li>Every 2 weeks on Thursday 13:00 - 14:00 ET</li> <li>Zoom</li> <li>Meeting notes</li> </ul>"},{"location":"community/conduct/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"community/conduct/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"community/conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the overall   community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or advances of   any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email address,   without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"community/conduct/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"community/conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official email address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"community/conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at lind-project-reporting@googlegroups.com. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"community/conduct/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"community/conduct/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"community/conduct/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"community/conduct/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"community/conduct/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"community/conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"community/team/","title":"Lind-WASM Team","text":""},{"location":"community/team/#advisor","title":"Advisor","text":"Justin Cappos  Professor, NYU  GitHub Email"},{"location":"community/team/#maintainers","title":"Maintainers","text":"Nick Renner  PhD Candidate, NYU  GitHub Email Yuchen (Dennis) Zhang  Post-doctoral researcher, NYU  GitHub Email Yaxuan (Alice) Wen  PhD Student, NYU  GitHub Email Qianxi Chen  Undergraduate Research Lead, NYU  GitHub Email"},{"location":"community/team/#outside-collaborators","title":"Outside Collaborators","text":"Marcela Melara  Intel Labs  GitHub Email"},{"location":"contribute/","title":"Contributing","text":"<p>The Lind sandbox is developed in the lind-wasm monorepo on GitHub. You can find the documentation assets, including this site, in the <code>lind-wasm/docs</code> subdirectory. Please contribute to the Lind project by submitting issues or pull requests to these repositories.</p> <p>To report a security issue, please refer to the Security Policy!</p> <p>Continue reading the pages in this section for detailed guidelines about writing code, tests, documentation, and more.</p>"},{"location":"contribute/add-docs/","title":"How to Add Documentation","text":"<p>Built with mkdocs and material, and hosted on GitHub pages: lind-project.github.io/lind-wasm.</p> <p>You can improve the docs by editing the files below. See <code>mkdocs</code> and <code>material</code> user guides for details. And don't forget to try out your changes locally!</p>"},{"location":"contribute/add-docs/#important-files","title":"Important files","text":"<ul> <li><code>.github/workflows/docs.yml</code>: Auto-deploys on push to <code>main</code> (e.g. on PR merge)</li> <li><code>mkdocs.yml</code>: Site config (e.g. navigation and plugins)</li> <li><code>docs/</code>: Site sources</li> </ul>"},{"location":"contribute/add-docs/#build-site-locally","title":"Build site locally","text":"<pre><code># Install requirements (hint: use a virtual environment)\npip install mkdocs-material\n\n# Run dev server and check output!\nmkdocs serve\n</code></pre> <p>Note</p> <p>Please also document your implementation source code following the used programming language's standards.</p>"},{"location":"contribute/compile-with-rust/","title":"Compiling Rust Code with <code>lind-glibc</code> (Shared Memory Enabled)","text":"<p>To compile Rust programs against <code>lind-glibc</code>:</p> <ul> <li>Ensure that the <code>scripts/cargo-lind_compile</code> script exists in <code>PATH</code></li> <li>Run <code>cargo lind_compile</code> at the root of your Rust crate.</li> </ul> <p><code>cargo-lind-compile</code> is a drop-in replace for <code>cargo build</code>. It supports the same flags (such as --release) and is intended to be used in same contexts.</p> <p>Internally, <code>cargo lind_compile</code> runs <code>cargo build</code> with the configurations detailed below.</p> <p>It then runs <code>lind-compile --opt-only</code> on this output <code>.wasm</code> binary to optimize it in place.</p> <p>Alternatively, you can use <code>lind-cargo-build</code> at the root of your Rust crate to run this script.</p>"},{"location":"contribute/compile-with-rust/#1-cargo-configuration-cargoconfigtoml","title":"1. Cargo Configuration (<code>.cargo/config.toml</code>)","text":"<p>Create or modify <code>.cargo/config.toml</code> as follows (based on <code>scripts/rust/config.toml.template</code>):</p> <pre><code>[build]\n# Compile all Rust code for WASI Preview 1\ntarget = \"wasm32-wasip1\"\n\n[target.wasm32-wasip1]\n# Use lind\u2019s custom clang wrapper for glibc-based WASI linking\nlinker = \"/home/lind-wasm/scripts/wasip1-clang.sh\"\n\nrustflags = [\n  # Do not use Rust\u2019s built-in self-contained WASI linker\n  \"-C\", \"link-self-contained=no\",\n\n  # Enable WebAssembly features required for shared memory\n  # - atomics: required for multi-threading\n  # - bulk-memory: required for memory.copy / memory.fill\n  # - crt-static: ensure static runtime linking\n  \"-C\", \"target-feature=+crt-static,+atomics,+bulk-memory\",\n\n  # Import and export the linear memory so the runtime can control it\n  \"-C\", \"link-arg=-Wl,--import-memory\",\n  \"-C\", \"link-arg=-Wl,--export-memory\",\n\n  # Enable shared linear memory (threads proposal)\n  \"-C\", \"link-arg=-Wl,--shared-memory\",\n\n  # Set maximum memory size (64 MiB)\n  \"-C\", \"link-arg=-Wl,--max-memory=67108864\",\n\n  # Export stack symbols required by lind runtime\n  \"-C\", \"link-arg=-Wl,--export=__stack_pointer\",\n  \"-C\", \"link-arg=-Wl,--export=__stack_low\",\n]\n</code></pre>"},{"location":"contribute/compile-with-rust/#why-this-is-necessary","title":"Why this is necessary","text":"<ul> <li>Shared memory requires <code>atomics + bulk-memory</code></li> <li>These features must be enabled for both your crate and <code>std</code></li> <li>Rust\u2019s prebuilt <code>std</code> does not include these features by default</li> <li>Therefore, <code>std</code> must be rebuilt explicitly</li> </ul>"},{"location":"contribute/compile-with-rust/#2-custom-linker-wrapper-scriptswasip1-clangsh","title":"2. Custom Linker Wrapper (<code>scripts/wasip1-clang.sh</code>)","text":"<p>The following script replaces Cargo\u2019s default linker and ensures that:</p> <ul> <li><code>lind-glibc</code> is used instead of WASI libc</li> <li>The correct <code>crt1.o</code> startup object is injected</li> <li><code>pthread</code> and glibc are linked properly</li> <li>All Rust-provided linker arguments are preserved</li> </ul>"},{"location":"contribute/compile-with-rust/#linker-script","title":"Linker Script","text":"<pre><code>#!/usr/bin/env bash\nset -euo pipefail\n\n# Path to lind-glibc sysroot\nSYSROOT=/home/lind-wasm/src/glibc/sysroot\nLIBDIR=\"$SYSROOT/lib/wasm32-wasi\"\nCRT1=\"$LIBDIR/crt1.o\"\n\n# Sanity checks (fail early with a clear message)\n[ -r \"$CRT1\" ] || { echo \"Missing $CRT1\"; exit 1; }\n[ -d \"$LIBDIR\" ] || { echo \"Missing $LIBDIR\"; exit 1; }\n\n# Base clang invocation\ncmd=(\n  clang\n  --target=wasm32-unknown-wasip1\n  --sysroot=\"$SYSROOT\"\n  -nostartfiles        # Prevent clang from injecting its own crt1.o\n)\n\n# Forward all arguments from rustc unchanged\ncmd+=(\"$@\")\n\n# Inject lind-glibc startup object and libraries\ncmd+=(\n  \"$CRT1\"\n  -L\"$LIBDIR\"\n  -lc                  # lind-glibc\n  -pthread             # enable pthread support\n)\n\n# Print the final command for debugging (stderr keeps rustc output clean)\necho \"[clang wrapper exec]\" \"${cmd[@]}\" 1&gt;&amp;2\n\n# Execute the linker\nexec \"${cmd[@]}\"\n</code></pre>"},{"location":"contribute/compile-with-rust/#why-this-script-exists","title":"Why this script exists","text":"<p>Rust\u2019s default WASI linker:</p> <ul> <li>Uses WASI-libc instead of glibc</li> <li>Does not support lind\u2019s threading and memory model</li> <li>Cannot inject a custom <code>crt1.o</code></li> </ul>"},{"location":"contribute/compile-with-rust/#this-wrapper-ensures-full-control-over-startup-libc-and-threading-behavior","title":"This wrapper ensures full control over startup, libc, and threading behavior.","text":""},{"location":"contribute/compile-with-rust/#3-build-rust-with-a-custom-std","title":"3. Build Rust with a Custom <code>std</code>","text":"<p>After configuring Cargo, compile your Rust project using nightly and rebuild the standard library:</p> <pre><code>cargo build -Z build-std=std,panic_abort\n</code></pre> <p>Alternatively, you can add the following to <code>.cargo/config.toml</code>, which achieves the same effect and is often easier to avoid missing during builds:</p> <pre><code>[unstable]\nbuild-std = [\"std\", \"panic_abort\"]\n</code></pre> <p>This ensures that <code>std</code> is always rebuilt with the required features whenever you run <code>cargo build</code>.</p>"},{"location":"contribute/compile-with-rust/#what-this-does","title":"What this does","text":"<ul> <li>Forces Rust to rebuild <code>std</code> for <code>wasm32-wasip1</code></li> <li>Applies your <code>rustflags</code> to <code>std</code> itself</li> <li>Enables atomics + bulk-memory inside <code>libstd</code></li> </ul>"},{"location":"contribute/debug-programs/","title":"Debugging","text":""},{"location":"contribute/debug-programs/#debugging-with-gdb","title":"Debugging with GDB","text":"<p>To debug a WebAssembly module using GDB, ensure that your module is compiled with debugging information (e.g., using the -g flag during compilation). Additionally, Wasmtime itself must be compiled in debug mode (i.e., without the --release flag) to enable effective debugging of both the runtime and the module. This allows GDB to access symbol information from both your program and Wasmtime.</p> <p>Note: Current limitations in GDB support for WebAssembly include lack of instruction-level inspection. Commands like <code>layout split</code> and <code>si</code> (step instruction) may break the terminal. It\u2019s recommended to use <code>layout src</code> for source-level debugging.</p>"},{"location":"contribute/debug-programs/#running-gdb-with-wasmtime","title":"Running GDB with Wasmtime","text":"<p>Use the following command to start GDB with Wasmtime:</p> <pre><code>gdb --args ../wasmtime/target/debug/wasmtime run -D debug-info -O opt-level=0 malloc-test.wasm\n</code></pre> <p>Explanation of arguments:</p> <ul> <li><code>gdb --args</code>: Passes arguments to the program through GDB.</li> <li><code>../wasmtime/target/debug/wasmtime run</code>: Runs your WebAssembly module using the Wasmtime binary.</li> <li><code>-D debug-info</code>: Enables Wasmtime\u2019s debug information support.</li> <li><code>-O opt-level=0</code>: Disables optimizations for easier debugging.</li> </ul>"},{"location":"contribute/debug-programs/#example-debugging-session","title":"Example Debugging Session","text":"<ol> <li> <p>Start GDB    Launch GDB with Wasmtime and your WebAssembly module:    <pre><code>gdb --args ../wasmtime/target/debug/wasmtime run -D debug-info -O opt-level=0 malloc-test.wasm\n</code></pre></p> </li> <li> <p>Set Breakpoints    In the GDB prompt, set breakpoints as needed:    <pre><code>(gdb) break main\n</code></pre></p> </li> <li> <p>Run the Program    Start execution:    <pre><code>(gdb) run\n</code></pre></p> </li> <li> <p>Inspect and Debug    Use GDB commands to step through and inspect your code:    <pre><code>(gdb) next\n(gdb) print p\n(gdb) continue\n</code></pre></p> </li> </ol>"},{"location":"contribute/debug-programs/#additional-resources","title":"Additional Resources","text":"<ul> <li>Wasmtime Documentation</li> <li>GDB Manual</li> </ul>"},{"location":"contribute/debug-programs/#other-debugging-techniques","title":"Other Debugging Techniques","text":""},{"location":"contribute/debug-programs/#disabling-signals-for-debugging","title":"Disabling Signals for Debugging","text":"<p>The <code>signal-disable</code> feature added in this PR allows <code>lind-wasm</code> to run binaries without inserting Wasmtime epoch signals, which is useful for debugging purposes. When this feature is enabled, the signal handler is not set, and any unexpected signals (e.g., timeouts or faults) will cause the program to crash directly in RawPOSIX, making issues easier to trace.</p> <p>\u26a0\ufe0f Warning: This feature is intended for debugging only and should not be used in production environments.</p> <p>To use this feature, compile <code>lind-wasm</code> with the <code>signal-disable</code> feature enabled. Here\u2019s how to do it:</p> <p>Building with the Feature:</p> <p>From the root of the repository, navigate to <code>src/wasmtime</code> and build with the <code>signal-disable</code> feature:</p> <pre><code>cd src/wasmtime\n\n# Build lind-wasm with the signal-disable feature\ncargo build --features signal-disable\n</code></pre>"},{"location":"contribute/debug-programs/#debugging-at-wasmwat-level","title":"Debugging at WASM/WAT Level","text":"<p>Two host-defined functions, <code>lind_debug_num()</code> and <code>lind_debug_str()</code>, are imported into the compiled WASM binary to support debugging at the WASM/WAT level. These functions facilitate debugging at the WASM/WAT level, allowing for the inspection of stack values and memory contents in environments where traditional debuggers (like GDB) cannot easily attach or provide visibility.</p> <p>Building with the Feature:</p> <p>Build the project from the root of the repository with <code>lind-debug</code>:</p> <pre><code>make lind-debug\n</code></pre> <p>Usage:</p> <ol> <li>Decompile the WASM binary</li> </ol> <p>Convert existing <code>.wasm</code> file to <code>.wat</code> format:</p> <p><code>bash  wasm2wat &lt;filename.wasm&gt; --enable-all -o &lt;filename.wat&gt;</code></p> <ol> <li>Add Debug Calls</li> </ol> <p>Open the <code>.wat</code> file and locate the area to inspect. Since these functions return their input back to the stack, you must either use the returned value or drop it to maintain stack integrity.</p> <p>Example: Debugging an Integer</p> <pre><code>;; Push a value or local onto the stack\nlocal.get 0\n;; Call the debugger (prints value to host stderr)\ncall $__lind_debug_num\n;; Drop the returned value to keep the stack clean\ndrop\n</code></pre> <p>Example: Debugging a String</p> <pre><code>;; Push the memory offset (pointer) where the string starts\ni32.const 1024\n;; Call the debugger (prints value to host stderr)\ncall $__lind_debug_str\n;; Drop the returned value to keep the stack clean\ndrop\n</code></pre> <p>\u26a0\ufe0f Warning: Use the offset of the pre-defined string in the binary. Defining a new string at an uncalculated offset might result in segmentation fault.</p> <ol> <li>Recompile to WASM</li> </ol> <p>After inserting debug calls, convert the file back to a binary:</p> <pre><code>wat2wasm &lt;filename.wat&gt; --enable-threads -o &lt;filename.wasm&gt;\n</code></pre>"},{"location":"contribute/dev-container/","title":"Development setup","text":"<p>To access an environment with the source code and tooling, there is a development image available as well. (Note: If you intend to use perf, you will need to install the appropriate <code>linux-tools-xxx</code> for your kernel)</p> <pre><code>docker pull --platform=linux/amd64 securesystemslab/lind-wasm-dev # this might take a while ...\ndocker run --platform=linux/amd64 -it --privileged --ipc=host --init --cap-add=SYS_PTRACE securesystemslab/lind-wasm-dev /bin/bash\n</code></pre> <p>This container can be built locally and the following args can be varied at build time for use on any branch or configuration needed.</p> <p><pre><code>docker build \\\n  --platform=linux/amd64 \\\n  --build-arg USERNAME=lind \\\n  --build-arg BRANCH_NAME=main \\\n  --build-arg LLVM_VERSION=llvmorg-16.0.4 \\\n  --build-arg CLANG_PACKAGE=clang+llvm-16.0.4-x86_64-linux-gnu-ubuntu-22.04 \\\n  -f ./Docker/Dockerfile.dev \\\n  -t lind-dev .\n</code></pre> The build process can be quite long, depending on system resources on the build machine. You can then run it with:</p> <pre><code>docker run --platform=linux/amd64 -it --privileged --ipc=host --init --cap-add=SYS_PTRACE lind-dev /bin/bash\n</code></pre>"},{"location":"contribute/docker-release-workflow/","title":"Docker Hub Release Workflow","text":"<p>The workflow builds the lind-wasm Docker image from the release stage of <code>Dockerfile.e2e</code> and pushes it to Docker Hub as <code>securesystemslab/lind-wasm</code>. It is manual-only (<code>workflow_dispatch</code>), so contributors must trigger it on demand.</p>"},{"location":"contribute/docker-release-workflow/#1-prerequisites","title":"1. Prerequisites","text":"Requirement Purpose Write rights on this repo lets you add secrets &amp; trigger the workflow Docker Hub access-token (or password) for <code>securesystemslab</code> used by GitHub\u00a0Actions to authenticate the Docker\u00a0Hub image push <p>Use a token, not your password: In Docker Hub \u25b8 Account Settings \u2192 Security, create a Read/Write access token and rotate it regularly.</p>"},{"location":"contribute/docker-release-workflow/#2-add-the-docker-hub-secret","title":"2. Add the Docker Hub secret","text":"<ol> <li>GitHub repo \u25b8 Settings \u2192 Secrets and variables \u2192 Actions </li> <li>New repository secret    * Name: <code>DOCKERHUB_PASSWORD</code>    * Value: your access token </li> <li>Click Add secret</li> </ol> <p>The workflow references it as <code>secrets.DOCKERHUB_PASSWORD</code>. See GitHub\u2019s guide: Using secrets in GitHub Actions.</p>"},{"location":"contribute/docker-release-workflow/#3-run-the-workflow-manual-trigger","title":"3. Run the workflow (manual trigger)","text":"<ol> <li>Open the repo\u2019s Actions tab.  </li> <li>Select Build &amp; push lind-wasm image.  </li> <li>Click Run workflow, choose a branch (defaults to <code>main</code>), then Run.  </li> <li>Watch the logs: you should see build \u2192 login \u2192 push succeed.</li> </ol> <p>For details, check GitHub\u2019s Manually running a workflow guide.</p>"},{"location":"contribute/docker-release-workflow/#4-what-the-workflow-does","title":"4. What the workflow does","text":"<ol> <li>Checkout the repository code.  </li> <li>Build the Docker image from the release stage of <code>Dockerfile.e2e</code>.  </li> <li>Login to Docker Hub with <code>DOCKERHUB_PASSWORD</code>.  </li> <li>Tag &amp; push:    * <code>securesystemslab/lind-wasm:&lt;GIT_SHA&gt;</code> \u2013 every build    * <code>securesystemslab/lind-wasm:latest</code> \u2013 every build</li> </ol>"},{"location":"contribute/e2e-testing/","title":"End-to-End testing","text":"<p>Multi-stage .e2e flow for lind-wasm end-to-end testing and image creation.</p> <ul> <li>Installs build dependencies</li> <li>Builds wasmtime, glibc, and a sysroot for clang cross-compilation</li> <li>A. Runs end-to-end tests (default)</li> <li>B. Creates a Docker image with the lind-wasm toolchain</li> <li>C. Provides a base image for interactive development with the full source tree mounted</li> </ul> <p>NOTE The <code>test</code> stage (A) runs end-to-end tests on <code>docker build</code> and is optimized for build time and caching. It is not meant for <code>docker run</code>.  </p> <p>Use the <code>release</code> stage (B) to create an image that includes the full lind-wasm toolchain (for demos, experiments, etc.).  </p> <p>For development, you may want to build just the <code>base</code> stage (C) and mount the full source tree.</p> <p>The Dev image is automatically rebuilt weekly from <code>Docker/Dockerfile.dev</code> on <code>main</code> and pushed to Docker Hub as <code>securesystemslab/lind-wasm-dev:latest</code>.</p>"},{"location":"contribute/e2e-testing/#usage-a-test","title":"Usage A \u2014 test","text":""},{"location":"contribute/e2e-testing/#from-repo-root","title":"From repo root","text":"<p><code>docker build --platform=linux/amd64 -f Docker/Dockerfile.e2e .</code></p> <ul> <li> <p>Triggers the default test stage.</p> </li> <li> <p>Earlier stages build prerequisites (clang/LLVM, Rust, wasmtime, sysroot).</p> </li> <li> <p>The test stage executes make test during the build and fails the build on any test failure.</p> </li> <li> <p>Check the build log for the e2e report (the harness prints results.json).</p> </li> </ul>"},{"location":"contribute/e2e-testing/#usage-b-create-and-run-a-toolchain-image-release","title":"Usage B \u2014 create and run a toolchain image (release)","text":""},{"location":"contribute/e2e-testing/#build-a-runnable-toolchain-image","title":"Build a runnable toolchain image","text":"<p><code>docker build --platform=linux/amd64 -f Docker/Dockerfile.e2e -t release --target release .</code></p>"},{"location":"contribute/e2e-testing/#run-image","title":"Run image","text":"<p><code>docker run --platform=linux/amd64 -it release /bin/bash</code></p> <ul> <li> <p>Contains the lind-wasm toolchain (wasmtime + sysroot + scripts/tests).</p> </li> <li> <p>Intended for demos/experiments.</p> </li> <li> <p>Not designed to run make test directly (the Makefile isn\u2019t copied here).</p> </li> </ul>"},{"location":"contribute/e2e-testing/#usage-c-create-a-base-image-and-mount-the-source","title":"Usage C \u2014 create a base image and mount the source","text":"<p><code>docker build --platform=linux/amd64 -f Docker/Dockerfile.e2e -t dev --target base .</code></p> <p><code>docker run --platform=linux/amd64 -v $(PWD):/lind -w /lind -it dev /bin/bash</code></p> <ul> <li> <p>Use the <code>base</code> stage to match CI dependencies while keeping your source outside the image for fast, iterative editing.</p> </li> <li> <p>Inside the container, run <code>make build &amp;&amp; make test</code> to mirror CI exactly; the command exits non-zero on any e2e failure.</p> </li> </ul>"},{"location":"contribute/e2e-testing/#build-steps","title":"Build steps","text":""},{"location":"contribute/e2e-testing/#make-sysroot","title":"make sysroot","text":"<p>Runs <code>scripts/make_glibc_and_sysroot.sh</code> to:</p> <ul> <li> <p>Configure &amp; build glibc (WASM/WASI target) and compile additional NPTL/syscall bits and tiny ASM stubs.</p> </li> <li> <p>Collect selected <code>.o</code> objects (excluding objects defining <code>main</code>) and archive them into <code>src/glibc/sysroot/lib/wasm32-wasi/libc.a</code>; creates <code>libpthread.a</code>; installs headers under <code>src/glibc/sysroot/include/wasm32-wasi/</code>; and copies <code>crt1.o</code>.</p> </li> </ul>"},{"location":"contribute/e2e-testing/#make-wasmtime","title":"make wasmtime","text":"<ul> <li>Builds the embedded Wasmtime with Cargo (release) from <code>src/wasmtime/</code>.</li> </ul>"},{"location":"contribute/e2e-testing/#make-test","title":"make test","text":"<p>Runs <code>scripts/wasmtestreport.py</code> which:</p> <ul> <li> <p>Discovers tests from the repository\u2019s test trees and honors <code>skip_test_cases.txt</code>.</p> </li> <li> <p>Organizes results (e.g., deterministic / non_deterministic groups), writes <code>results.json</code> (and may render an HTML summary if enabled).</p> </li> <li> <p>The Makefile prints <code>results.json</code> and fails when any failures are present.</p> </li> </ul>"},{"location":"contribute/e2e-testing/#ci-overview-how-e2e-is-wired","title":"CI overview (how e2e is wired)","text":"<p>Workflow: <code>.github/workflows/e2e.yml</code></p> <p>High level:</p> <ul> <li> <p>Set up Docker Buildx for linux/amd64</p> </li> <li> <p>Build Docker/Dockerfile.e2e with GitHub Actions cache</p> </li> <li> <p>Execute the test stage (same behavior as Usage A)</p> </li> </ul>"},{"location":"contribute/e2e-testing/#caching","title":"Caching","text":""},{"location":"contribute/e2e-testing/#what-we-cache","title":"What we cache","text":"<ul> <li> <p>Buildx GHA layer cache (<code>cache-from/to: type=gha</code>) for apt/clang/rust/tooling and per-stage layers.</p> </li> <li> <p>Multi-stage outputs: <code>build-wasmtime</code> and <code>build-glibc</code> are mounted into <code>test</code>, so tests avoid rebuilding toolchains.</p> </li> </ul>"},{"location":"contribute/e2e-testing/#github-actions-semantics","title":"GitHub Actions semantics","text":"<ul> <li> <p><code>cache-from: type=gha</code> pulls layers from the hosted GitHub Actions cache.</p> </li> <li> <p><code>cache-to: type=gha,mode=max</code> pushes all reusable layers (not just the final image).</p> </li> <li> <p>The first cold run builds all layers; subsequent runs only rebuild changed layers, dramatically speeding up CI.</p> </li> </ul> <p>Note: GitHub Actions may evict cached layers over time; when that happens a run starts cold but still passes the same way.</p>"},{"location":"contribute/e2e-testing/#local-build-with-cache","title":"Local build with cache","text":""},{"location":"contribute/e2e-testing/#one-time-createselect-a-builder","title":"One-time: create/select a builder","text":"<p><code>docker buildx create --use --name lind-builder || docker buildx use lind-builder</code></p>"},{"location":"contribute/e2e-testing/#build-with-cache-importexport","title":"Build with cache import/export","text":"<p><code>docker buildx build --platform=linux/amd64 -f Docker/Dockerfile.e2e --cache-from type=local,src=~/.cache/docker-buildx --cache-to type=type=local,dest=.~/.cache/docker-buildx,mode=max .</code></p> <p>CI typically uses type=gha; locally a local cache is simple and reliable.</p>"},{"location":"contribute/e2e-testing/#troubleshooting","title":"Troubleshooting","text":"<ul> <li> <p>Apple Silicon / wrong arch \u2192 add --platform=linux/amd64 to all build/run commands.</p> </li> <li> <p>Slow first build \u2192 increase Docker memory (\u2248 6\u20138 GB) to accommodate sysroot/wasmtime builds.</p> </li> <li> <p>Stale artifacts \u2192 run make clean/make distclean and rebuild inside the dev (base) container.</p> </li> <li> <p>Cache debugging \u2192 add --progress=plain to docker build to see which step invalidated.</p> </li> </ul>"},{"location":"contribute/security/","title":"Security Issues and Bugs","text":"<p>Security issues can be reported to maintainers privately via GitHub:</p> <ul> <li>Report new vulnerability</li> </ul> <p>Please do not use the GitHub issue tracker to submit vulnerability reports. The issue tracker is intended for bug reports and to make feature requests.</p>"},{"location":"contribute/styleguide/","title":"Rust Style Guide","text":"<p>Rust code in <code>lind-wasm</code> follows the default Rust style and should be auto-formatted:</p> <pre><code>cargo fmt --all --manifest-path src/wasmtime/Cargo.toml\ncargo fmt --all --manifest-path src/lind-boot/Cargo.toml\n</code></pre>"},{"location":"contribute/testing/","title":"Testing","text":"<p>This document is a practical guide to setting up and using the Lind testing infrastructure. It outlines the steps needed to run the test suites, execute unit tests and grate tests, and understand the results produced by the test suite, and how to contribute new tests to the framework.</p> <p>Since Lind is currently limited to the AMD64 architecture, Docker is used to provide a consistent and controlled testing environment across different host systems. You can install Docker from its website.</p>"},{"location":"contribute/testing/#testing-workflow","title":"Testing Workflow","text":"<ol> <li>Clone the repo using  <pre><code>git clone https://github.com/Lind-Project/lind-wasm.git\n</code></pre></li> <li>Change directory to repo  <pre><code>cd lind-wasm\n</code></pre></li> <li>Build Docker Image  <pre><code>docker build --platform=linux/amd64 -f Docker/Dockerfile.e2e -t dev --target base .\n</code></pre></li> <li>Run the image  <pre><code># Note: The `-v` option mounts your repo into the container. This means, you can\n# live-edit the files in the container using your host editor. And files created\n# or edited in the container, e.g. when running `make`, persist on the host.\n\ndocker run --platform=linux/amd64 -v $(PWD):/lind -w /lind -it dev /bin/bash\n</code></pre></li> <li>Build toolchain (glibc and wasmtime) <pre><code># this may take a while ...\nmake lind-boot sysroot\n</code></pre></li> <li>Run the test suite  <pre><code>./scripts/wasmtestreport.py\n</code></pre> Run <code>scripts/wasmtestreport.py --help</code> to list available usage options.</li> </ol>"},{"location":"contribute/testing/#directory-structure","title":"Directory Structure","text":"<ul> <li><code>tests/unit-tests/</code>: Folder containing all <code>.c</code> test cases for general testing.</li> <li><code>tests/grate-tests/</code>: Folder containing all <code>.c</code> test cases for grate testing.</li> <li><code>expected/</code>: Directory under each test folder for expected output files.</li> <li><code>testfiles/</code>: Extra files needed by tests, copied into Lind FS.</li> </ul>"},{"location":"contribute/testing/#how-to-add-test-cases","title":"How to add test cases","text":"<p>To add test cases, a file with .c extension containing c code can be added to the appropriate folder in the <code>tests/unit-tests</code> or <code>tests/grate-tests</code> folder. During the test suite run, the test case will be picked up and run. Wherever possible each  test compares the output of running the program in lind and on linux. If these output differ,  this is considered a failure.</p> <p>Any compilation or runtime failure on either linux or lind-wasm is considered a failure.</p>"},{"location":"contribute/testing/#unit-test-suite","title":"Unit test suite","text":""},{"location":"contribute/testing/#what-test-suite-does","title":"What test suite does","text":"<ol> <li> <p>Test Case Collection: Scans <code>unit-tests</code> folder for <code>.c</code> files.</p> </li> <li> <p>Filtering: Applies include/exclude filters (<code>--run</code>, <code>--skip</code>, and    <code>skip_test_cases.txt</code>).</p> </li> <li>Test Execution: Compiles and executes each test case twice, with native    gcc and with lind-wasm, and records the output. (note: gcc is skipped for    tests with expected output fixture, and for tests with non-deterministic output)</li> <li>Comparing Outputs:  Marks test as successful, if outputs match    (note: non-deterministic tests always succeed, if compilation and execution    succeeds)</li> <li>Reporting: Test results are written to a JSON- and  an HTML-formatted    report in the current working directory. The reports include a summary of the    full test run, and status, error type, and output of each test case.</li> </ol>"},{"location":"contribute/testing/#error-types","title":"Error Types","text":"<p>The output will show the total number of test cases, along with counts for successes, failures, and each of the following error types:</p> <ul> <li>\"Failure_native_compiling\": Failed during GCC compiling</li> <li>\"Failure_native_running\": Failed while running GCC compiled binary</li> <li>\"Native_Segmentation_Fault\": Segmentation Fault while running GCC binary</li> <li>\"Native_Timeout\": Timed Out during GCC run</li> <li>\"Lind_wasm_compiling\": Failed during compilation using lind-wasm</li> <li>\"Lind_wasm_runtime\": Failed while running lind-wasm compiled binary</li> <li>\"Lind_wasm_Segmentation_Fault\": Segmentation Fault while running wasm binary</li> <li>\"Lind_wasm_Timeout\": Timed out During Lind Wasm run</li> <li>\"Output_mismatch\": Mismatch in GCC and Wasm outputs</li> <li>\"Unknown_Failure\": Unknown Failure</li> </ul> <p>The outputs are split into deterministic and non-deterministic based on how the lind-wasm outputs are compared to the native gcc output. </p>"},{"location":"contribute/testing/#example-combined-usage","title":"Example Combined Usage","text":"<pre><code>./scripts/wasmtestreport.py \\\n  --generate-html \\\n  --skip config_tests file_tests \\\n  --timeout 10 \\\n  --output results_json \\\n  --report test_report  \n</code></pre> <p>This will:</p> <ul> <li>Skip specified folders</li> <li>Use a 10-second timeout</li> <li>Save output as <code>results_json.json</code></li> <li>Generate a report <code>test_report.html</code></li> </ul>"},{"location":"contribute/testing/#grate-tests","title":"Grate tests","text":"<p>Grate tests are designed to validate a special feature in lind-wasm: the grate mechanism. The concept of a grate is defined in internal/3i.</p> <p>Grate tests ensure that the grate\u2013cage interaction model behaves correctly under the expected fork/exec execution semantics.</p>"},{"location":"contribute/testing/#structure-of-a-grate-test","title":"Structure of a Grate Test","text":"<p>Each grate test must contain at least two source files:</p> <ul> <li>A grate file</li> <li>A cage file</li> </ul>"},{"location":"contribute/testing/#grate-tests-format","title":"Grate tests Format","text":"<p>Naming Convention</p> <pre><code>&lt;cage_name&gt;.c\n&lt;cage_name&gt;_grate.c\n</code></pre> <p>Example:</p> <pre><code>hello.c\nhello_grate.c\n</code></pre> <p>Test Requirements</p> <p>Each grate test must:</p> <ul> <li>Has dispatcher function called <code>pass_fptr_to_wt</code></li> <li>Determine test success internally</li> <li>Exit with EXIT_FAILURE if the test fails</li> <li>Exit normally (e.g., EXIT_SUCCESS) on success</li> </ul> <p>Tests are expected to be self-validating.</p> <p>Execution Model</p> <p>Grate tests must follow the fork/exec model:</p> <ul> <li>The grate file executes first.</li> <li>The grate performs a fork().</li> <li>The child process becomes the cage.</li> <li>The grate registers the necessary handler(s).</li> <li>The child performs exec() to execute the cage file.</li> </ul>"},{"location":"contribute/testing/#how-to-build-and-run","title":"How to Build and Run","text":"<p>Prerequisite</p> <p>Make sure the lind-wasm runtime has already been compiled.</p> <p>Step 1 \u2014 Compile the Grate</p> <pre><code>lind-clang --compile-grate &lt;cage_name&gt;_grate.c\n</code></pre> <p>This produces <code>&lt;cage_name&gt;_grate.cwasm</code></p> <p>Step 2 \u2014 Compile the Cage</p> <pre><code>lind-clang &lt;cage_name&gt;.c\n</code></pre> <p>This produces <code>&lt;cage_name&gt;.cwasm</code></p> <p>Step 3 \u2014 Run the Test</p> <pre><code>lind-wasm &lt;cage_name&gt;_grate.cwasm &lt;cage_name&gt;.cwasm\n</code></pre>"},{"location":"contribute/toolchain/","title":"Lind toolchain","text":"<p>The toolchain to build and run lind programs consists of the following components:</p> <ul> <li>Clang with WebAssembly System Interface (WASI) support to build glibc   and lind programs</li> <li>A custom glibc used as sysroot to build   lind programs</li> <li>A custom <code>wasm-opt</code> binary to enable multi-processing   in lind programs</li> <li>A custom WebAssembly runtime (<code>wasmtime</code>) with   RawPOSIX to run lind programs</li> <li>Cargo to build <code>wasmtime</code></li> </ul> <p>This document gives an overview of how the toolchain is built. The build process is automated with Docker, make and custom shell scripts. Please refer to the relevant files linked below for details about the build commands and used options.</p>"},{"location":"contribute/toolchain/#building-the-toolchain-step-by-step","title":"Building the toolchain step by step","text":"<ol> <li> <p>Install system dependencies (see <code>apt</code> in Dockerfile)</p> </li> <li> <p>Download Clang and install builtins (see \"Install clang\" in Dockerfile)</p> <p>Clang supports the WASI cross-compilation target out of the box, provided the necessary compiler runtime builtins and a matching sysroot. See wasi-sdk docs for details.</p> <p>A pre-built Clang can be downloaded from the llvm-project releases page. Matching builtins are available in the lind-wasm repo under <code>src/glibc/wasi</code>.</p> </li> <li> <p>Build glibc and generate sysroot (see <code>make sysroot</code>)</p> <ol> <li> <p>Configure and compile glibc for the WASI target with Clang</p> </li> <li> <p>Compile extra files:</p> <ul> <li><code>nptl/pthread_create.c</code></li> <li><code>lind_syscall/lind_syscall.c</code></li> <li><code>lind_syscall/addr_translation.c</code></li> <li><code>csu/wasm32/wasi_thread_start.s</code></li> <li><code>csu/wasm32/set_stack_pointer.s</code></li> </ul> </li> <li> <p>Generate sysroot</p> <p>Combine the built object files into a single archive file and copy along with headers and a pre-built C runtime into a sysroot directory structure as required by Clang.</p> </li> </ol> </li> <li> <p>Build custom wasmtime (see <code>make wasmtime</code>)</p> <p>Builds <code>src/wasmtime</code> workspace. Custom dependencies <code>fdtables</code>, <code>RawPOSIX</code>   and <code>sysdefs</code> are included in the build automatically.</p> </li> </ol> <p>A customized <code>wasm-opt</code> binary is included in the lind-wasm repo under <code>tools/binaryen/bin</code> and can be used as is.</p>"},{"location":"contribute/toolchain/#next-steps","title":"Next steps","text":"<p>Automate the build and run programs with <code>Docker</code> and <code>make</code>.</p>"},{"location":"internal/","title":"Internal Documentation","text":"<p>This section contains internal implementation notes and references for core Lind-Wasm components (libc, Wasmtime integration, RawPOSIX, and subsystem topics).</p>"},{"location":"internal/3i/","title":"3i and Grates","text":""},{"location":"internal/3i/#i-threei","title":"I. ThreeI","text":"<p>3i (Three-I) provides a general means for cages (and grates) to make system calls and intercept system calls via a programmable system call table.  The goal is to enable complex functionality without modifying the microvisor or increasing the microvisor's trusted computing base. </p>"},{"location":"internal/3i/#11-motivation","title":"1.1 Motivation","text":"<p>In a traditional Linux environment, extending or intercepting system calls (e.g., adding a new filesystem, tracing, or filtering calls) requires kernel modifications or mechanisms such as ptrace, which incur heavy overhead and depend on kernel-level mediation.</p> <p>3i eliminates these constraints by introducing a user-space routing layer between cages, grates, and the underlying microvisor. Calls can be dispatched directly between grates or delegated to the microvisor when necessary, achieving kernel-level extensibility while keeping all new logic external to the kernel\u2019s TCB.</p>"},{"location":"internal/3i/#12-design-goals","title":"1.2 Design Goals","text":"<p>3i is designed as a runtime-agnostic interposition layer that can operate on top of a wide range of isolation backends (e.g., software sandboxes, hardware-assisted memory protection, etc.) to execute arbitrary code. Its core goal is to provide a uniform mechanism for inter-cage call routing -- including system call interception, syscall customization, and cross-cage RPC -- without being tied to any specific runtime.</p> <p>To achieve this, 3i exposes an abstraction that allows runtimes to register arbitrary entry and exit hooks, implemented as plain C-ABI function pointers. These hooks allow each backend to integrate its own cage-management requirements (e.g., switching execution contexts, updating thread-local state, or preparing runtime metadata) into the call path. Because 3i itself never assumes the presence of a particular runtime structure or object model, backend-specific behavior remains fully encapsulated in the corresponding adapter layer, leaving 3i\u2019s core logic small, generic, and portable.</p>"},{"location":"internal/3i/#13-high-level-concepts","title":"1.3 High-level Concepts","text":"<p>[todo] - add the figure of general lind</p> <p>In traditional operating systems, a process makes a system call which traps into the kernel.  Every process which makes a system call ends up trapping into the same kernel routine.  In essence, there is one system call table which is shared by every process.</p> <p>In contrast, in Lind, 3i provides a per-cage, per-system-call table. Each cage may define a function to serve as a system-call handler and register it for a specific system call (via <code>register_handler</code>). As a result, every system call of every cage can have its own distinct handler. When a cage issues a system call (<code>make_syscall</code>), the invocation is dispatched to the handler registered for that particular system call in that particular cage. Because handler tables are cage-local, multiple cages may register different handlers for the same system call without interfering with one another.</p> <p>Specifically, 3i supports the following scenarios:</p> <ol> <li> <p>Per-call routing within a single cage:    Different system calls issued by the same cage can be handled by different grates (or RawPOSIX) by registering distinct handlers for each system call.</p> </li> <li> <p>Shared handlers across multiple cages:    Multiple cages may register the same handler function (provided by a grate) by invoking <code>register_handler</code> with different <code>cageid</code>s, enabling controlled sharing of system call implementations across cages.</p> </li> </ol> <p>As a term of convenience, we call a cage which processes system calls a \"grate\".  This is meant to convey the mental model of a cage calling down towards the microvisor / kernel and having a grate filter or transform or handle those system calls.  However, a grate is simply a cage and there is no special handling code or permission for it in 3i or the rest of the system.  A grate may tend to make different system calls from a normal application, but it is still a cage, much like strace is still a normal Linux process that happens to use system calls like ptrace which are otherwise rare.</p> <p>One important feature needed by a grate is the ability to read and write the memory of a cage which makes a system call it intercepts.  For example, to handle a write system call, the grate must be able to read data out of the calling cage's buffer, which involves reading the calling cage's memory.  3i provides a function ( copy_data_between_cages ) to enable this feature safely.  </p> <p>Consider a grate that wishes to count how many times a specific cage invokes the <code>write</code> system call. The grate must increment its counter and then re-issue the <code>write</code> call on behalf of the originating cage. However, copying the user buffer into the grate\u2019s own address space would be wasteful when the grate merely wants to observe and forward the call. To support this use case, <code>make_syscall</code> allows each argument of the system call to be annotated with a source cageid. The grate can therefore perform the forwarded <code>write</code> using its own system-call table while specifying that the buffer pointer resides in the calling cage\u2019s address space. This per-argument cage identifier enables grates to distinguish which cage originated a system call and to safely access or forward data without unnecessary copying. This mechanism is required by many grates that interpose on system calls issued by other cages.</p> <p>One final important feature of <code>make_syscall</code> is the ability for a grate to perform a system call as though another cage had issued it. Consider the <code>fork</code> system call: if a cage invokes <code>fork</code> and the grate simply executes a native <code>fork</code>, the grate -- not the originating cage -- would be duplicated. To prevent this, each <code>make_syscall</code> invocation explicitly specifies the target cage whose state and identity the system call should operate on.</p> <p>Finally, 3i functions such as <code>register_handler</code> and <code>copy_data_between_cages</code> are themselves treated as system calls within 3i. They are 3i-specific APIs that participate in the same interception and dispatch framework, enabling grates to interpose on operations performed by other grates. This is the key mechanism that is used to provide security in 3i -- the ability to make a grate that can correctly namespace and enforce protections between cages, including calls to 3i.</p>"},{"location":"internal/3i/#14-3i-function-calls","title":"1.4 3i Function Calls","text":"<p>[todo]: - a short instruction/example on how to write grates by using those functions</p> Caller Callee Function Interposable Remarks grate 3i <code>register_handler</code> Yes Register a handler for a syscall grate 3i <code>copy_handler_table_to_cage</code> Yes Overwrites the entire syscall handler table of a cage grate 3i <code>copy_data_between_cages</code> Yes Copies memory across cages grate 3i <code>make_syscall</code> No Call the registered handler for a syscall WASM / NaCl / RawPOSIX 3i <code>trigger_harsh_cage_exit</code> No Kill a cage: See detailed explanation below 3i / grate grate / RawPOSIX <code>harsh_cage_exit</code> Yes Notify a cage was killed: See detailed explaination below <p>NOTE: </p> <p>- Interposable in the table means whether these calls are made via the system call table and thus whether or not a grate could alter their behavior</p> <p>- Caller denotes the execution context that invokes the function (i.e., the component whose code initiates the transition into 3i or another cage). In other words, it represents the origin of the call site. A caller can be a grate, a normal cage, RawPOSIX, runtime, or 3i itself; the Callee column indicates which subsystem receives and executes the request.</p>"},{"location":"internal/3i/#register_handler","title":"<code>register_handler</code>","text":"<p>This function registers an interposition rule, mapping a syscall number from a source cage to a handler function in a destination grate or cage. Used for creating per-syscall routing rules that enable one cage to interpose or handle syscalls on behalf of another.</p>"},{"location":"internal/3i/#copy_handler_table_to_cage","title":"<code>copy_handler_table_to_cage</code>","text":"<p>This function copies the handler table used by a cage to another cage. This is often useful for calls like fork, so that a grate can later add or remove entries.</p>"},{"location":"internal/3i/#copy_data_between_cages","title":"<code>copy_data_between_cages</code>","text":"<p>This function copies memory across cages.  One common use of this is to read arguments which are passed by reference instead of by value.  The source and destination cages may each be different from the calling cage.  This may be useful for some grates.</p>"},{"location":"internal/3i/#make_syscall","title":"<code>make_syscall</code>","text":"<p>This function actually performs a 3i call. It is not interposable. This is the most commonly used and simplest API, despite the number of arguments.  All the code here does is route the call to the corresponding handler and deal with error situations.</p> <p>Note that this call is itself not interposable, since this is the base call used to route other calls and do the interposition.  In theory, this could be changed, but it doesn't seem useful to do so.</p> <p>This is the main entry point used by cages or grates to invoke system calls through the 3i layer. The function inspects the caller\u2019s interposition configuration (if any) and either routes the syscall to a grate for handling or directly invokes the corresponding function in the RawPOSIX layer.</p>"},{"location":"internal/3i/#trigger_harsh_cage_exit-and-harsh_cage_exit","title":"<code>trigger_harsh_cage_exit</code> and <code>harsh_cage_exit</code>","text":"<p>This is essentially a way for grates to clean up if a cage was abruptly killed (perhaps due to a signal).  <code>trigger_harsh_cage_exit</code> is triggered by the caging or signaling infrastructure to indicate that a cage will (uncleanly) exit. After receiving notification, 3i will cleanup the 3i data structure (which is the system call table) and then 3i will go through the respective grates until reaching 3i's version of the call by triggering <code>harsh_cage_exit</code>. This call can be thought of as notifying the grates and microvisor of the harsh exit of a program whose memory state cannot be relied upon. This is unlike the <code>exit_syscall</code>, which is performed by a functioning program with intact memory as part of its termination.</p> <p>Why not interposable? At the time <code>trigger_harsh_cage_exit</code> or <code>harsh_cage_exit</code> is invoked, the target Cage or Grate is assumed to have unreliable memory and control flow. During the execution of these calls, the syscall table of the target cage/grate is either being torn down or may already be corrupted, meaning the call path itself is no longer trustworthy.</p> <p>The cleanup process must complete system-level invariants such as: unmapping vmmap regions, cleaning fdtables, waking waiters, canceling schedulers or timers, etc. Allowing these calls to be interposable would permit third-party grates to inject arbitrary logic (e.g., blocking, allocation, or reentrancy), which could stall or disrupt the teardown sequence, resulting in resource leaks, deadlocks, or zombie cages/grates.</p>"},{"location":"internal/3i/#ii-prototype-implementation-lind-wasm","title":"II. Prototype Implementation - Lind-Wasm","text":"<p>[todo] - figure </p>"},{"location":"internal/3i/#21-background-wasmtime","title":"2.1 Background - Wasmtime","text":""},{"location":"internal/3i/#store","title":"Store","text":"<p>In Wasmtime, a <code>Store</code> is the top-level container that owns all runtime objects. A single <code>Store</code> may own multiple <code>Instance</code>s, and every <code>Instance</code> must belong to exactly one <code>Store</code>. All runtime items, such as Functions, Tables, Memories, and Globals, are allocated within the <code>Store</code> and are tied to its lifetime.</p>"},{"location":"internal/3i/#module-instance","title":"Module &amp; Instance","text":"<ul> <li>A <code>Module</code> is only a compiled binary: it contains code and type information but no runtime state.</li> <li>An <code>Instance</code> is the executable instantiation of a <code>Module</code> within a <code>Store</code>.</li> </ul> <p>You cannot read memory, table, globals, or call functions on a <code>Module</code>. All executable interactions happen through an <code>Instance</code>.</p>"},{"location":"internal/3i/#vmcontext","title":"VMContext","text":"<p>Each <code>Instance</code> has an internal data structure called <code>VMContext</code>. <code>VMContext</code> is a raw pointer used by the JIT-generated machine code. This has information about globals, memories, tables, and other runtime state associated with the current instance.</p>"},{"location":"internal/3i/#call-stack","title":"Call Stack","text":"<p>Although WebAssembly defines an abstract operand stack and structured control flow, Wasmtime lowers all function calls and stack frames to the native call stack of the executing host thread. Each Wasm function is compiled into a normal machine function that receives a <code>VMContext</code> pointer as an implicit first argument. Local variables, temporaries, and control-flow state are therefore represented using standard native stack slots and registers.</p> <p>Wasmtime attaches a <code>VMRuntimeLimits</code> structure to every <code>VMContext</code>, which stores a stack-limit pointer. At function-entry, compiled code inserts a prologue check comparing the current native stack pointer against this limit; exceeding it triggers a Wasmtime stack-overflow trap rather than a process-level segmentation fault.</p>"},{"location":"internal/3i/#memory","title":"Memory","text":"<p>Wasmtime implements each linear memory as a sandboxed region in the host virtual address space. At instantiation time, the runtime reserves a contiguous virtual range using <code>mmap</code> and commits only the portion required by the module\u2019s initial size.</p> <p>Each memory is represented internally by a <code>VMMemoryDefinition</code> structure embedded in the instance\u2019s <code>VMContext</code>. The <code>VMContext</code> is passed as an implicit argument to all JIT-compiled functions. Every load or store instruction is lowered to native code that first reads the memory\u2019s base pointer and current length from the <code>VMContext</code>, performs an explicit bounds check, and then translates the Wasm address into a native pointer (<code>base + offset</code>). </p>"},{"location":"internal/3i/#22-implementation","title":"2.2 Implementation","text":"<p>Lind-wasm implements a global runtime-state lookup and pooling mechanism for lind-wasm and lind-3i, enabling explicit, controlled transfers of execution across cages, grates, and threads.</p> <p>Unlike conventional WebAssembly execution models: where control flow is confined to a single Wasmtime <code>Store</code>, <code>Instance</code>, and linear call stack. Lind-wasm supports cross-instance and cross-module execution transfers. These transfers are required to implement POSIX-like process semantics (each process has its own state management) and lind-3i\u2019s inter-cage and inter-grate call model.</p> <p>To support this, lind-wasm must be able to:</p> <ul> <li>Identify the correct Wasmtime runtime state without relying on implicit \u201ccurrent execution context\u201d assumptions</li> <li>Re-enter an existing Wasm instance from outside its original call stack</li> <li>Support concurrent execution paths that operate on shared Wasm linear memory</li> </ul>"},{"location":"internal/3i/#execution-scenarios-requiring-runtime-lookup","title":"Execution Scenarios Requiring Runtime Lookup","text":"<ol> <li>Process-like Operations (<code>fork</code>, <code>exec</code>, <code>exit</code>)</li> </ol> <p>Operations such as fork, exec, and exit require Wasmtime instances to be created, cloned, or destroyed. However, the logic that performs the semantic handling of these operations may execute in a different cage or grate than the one that originally issued the system call.</p> <p>After RawPOSIX completes the semantic work, control must return to Wasmtime, not necessarily to the instance that initiated the call. As a result, lind-3i cannot rely on an implicit \u201ccurrent\u201d runtime state. Instead, it must explicitly retrieve the correct execution context:</p> <p>For <code>fork</code>, <code>exec</code>, and <code>exit</code>, these operations conceptually create,replace, or terminate the execution state of a process. After RawPOSIX completes the semantic handling, lind-wasm must resume execution in a Wasmtime instance associated with an arbitrary <code>cage_id</code>, which may differ from the calling cage. The appropriate runtime context is therefore retrieved by directly looking up the execution context associated with the target <code>cage_id</code>.</p> <ol> <li>Thread-like Operations</li> </ol> <p>Thread operations introduce additional execution contexts within the same cage. These contexts are not part of the main execution flow and cannot be recovered via a global \u201ccurrent\u201d state. Instead, lind-wasm explicitly looks up the runtime context associated with the corresponding <code>(cage_id, tid)</code> pair, ensuring correct control-flow transfer during thread creation, scheduling, and termination.</p> <ol> <li>Grate Calls (Cross-Module Execution Transfers)</li> </ol> <p>Grate calls represent explicit execution jumps between Wasm modules, such as:</p> <ul> <li>Cage -&gt; Grate</li> <li>Grate -&gt; RawPOSIX</li> <li>Grate -&gt; Grate</li> </ul> <p>These jumps are not standard Wasm function calls and cannot rely on a shared call stack or <code>Store</code>. Supporting them requires the ability to (1) Locate a runtime state belonging to a different module, and (2) Re-enter Wasm execution from outside the original stack frame. To achieve this, lind-wasm relies on the following invariant: Each Wasmtime <code>Store</code> contains exactly one Wasm <code>Instance</code>, and each thread executes within its own independent <code>Store</code> / <code>Instance</code> pair. The Wasmtime <code>VMContext</code> pointer uniquely identifies the execution state of a running instance. Given a valid <code>VMContext</code>, lind-wasm can recover the associated <code>Store</code> and <code>Instance</code> using Wasmtime internals. Moreover, since <code>VMContext</code> is the raw pointer, it also helps lind-wasm bypass the lifetime restriction of <code>Store</code> and <code>Instance</code>.</p>"},{"location":"internal/3i/#data-structure","title":"Data structure","text":"<p>Because <code>VMContext</code> is opaque and lifetime-managed internally by Wasmtime, this module stores it as a raw pointer wrapped in a minimal abstraction:</p> <pre><code>pub struct VmCtxWrapper {\n    pub vmctx: NonNull&lt;c_void&gt;,\n}\n</code></pre> <p>Lind-Wasm maintains two global, per-cage pools of <code>VMContext</code> pointers:</p> <ol> <li>General execution context lookup table</li> </ol> <p>The global <code>VMCTX_QUEUES</code> structure primarily manages execution contexts for the main thread (<code>tid = 1</code>) of each cage and indexed by <code>cage_id</code>. Each cage owns a FIFO queue that stores the execution contexts currently available to it. The total number of cages is fixed at startup (<code>MAX_CAGEID</code>).</p> <p>Importantly, table slots are never removed from the global pool. Instead, the slot contents(the queue) of each slot may be inserted or removed over time. When a cage terminates, its corresponding queue slot remains present, but its slot content is cleared and set to <code>None</code>.</p> <p>This design ensures that each table index always directly corresponds to a <code>cage_id</code>, eliminating the need for dynamic index management or lookup structures. As a result, <code>cage_id</code> can be used as a stable, constant-time index into the pool, reducing lookup overhead and avoiding additional search or indirection costs.</p> <pre><code>static VMCTX_QUEUES: OnceLock&lt;Vec&lt;Mutex&lt;VecDeque&lt;VmCtxWrapper&gt;&gt;&gt;&gt;;\n</code></pre> <ol> <li>Thread Handling and Execution Context Lookup</li> </ol> <p>To support thread-related operations, lind-wasm maintains a separate, thread-specific execution context table. This table is used only for non-main threads (<code>tid != 1</code>) and exists to support thread-related syscalls and thread <code>exit</code>. Each <code>(cage_id, tid)</code> maps to at most one <code>VMContext</code>. No pooling is performed. This table is not consulted for normal execution or grate calls.</p> <pre><code>static VMCTX_THREADS: OnceLock&lt;Vec&lt;Mutex&lt;HashMap&lt;u64, VmCtxWrapper&gt;&gt;&gt;&gt;;\n</code></pre>"},{"location":"internal/3i/#execution-flow","title":"Execution Flow","text":"<p>[todo]  - use cases, end-to-end steps (first) --&gt; explain each steps after that </p> <p>[ Cage A ]    \u2502    \u2502  (system call / grate call)    \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502      3i      \u2502 \u2502 (dispatcher) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502 redirect to wasmtime by <code>MAKE_SYSCALL</code>    \u2502    \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502   wasmtime   \u2502 \u2502              \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502 lookup target <code>cage_id</code>    \u2502    \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  Global VMContext Pool     \u2502 \u2502  get_vmctx(<code>cage_id</code> = G)  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502 returns <code>VmCtxWrapper</code>    \u2502 (raw <code>VMContext*</code>)    \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502   Wasmtime internals       \u2502 \u2502  recover <code>Store</code>/<code>Instance</code>\u2502 \u2502   from VMContext pointer   \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502 enter wasm execution    \u25bc [ Grate G ]    \u2502    \u2502 Return    \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502   Wasmtime internals       \u2502 \u2502set_vmctx(cageid, VMContext)\u2502 \u2502  put VMContext back to pool\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518</p> <p>Callback Definition (Wasmtime side):</p> <p>The C-ABI callback function knows how to re-enter the Wasm module via the unified entry function.</p> <p>Handler Registration:</p> <p>When the Wasm module calls <code>register_handler()</code>, the redirection information entry is extracted and passed to 3i.</p> <p>Cross-Cage Invocation:</p> <p>When a syscall from cage A is routed to grate B:</p> <ol> <li>the regular syscall reaches 3i via <code>make_syscall</code></li> <li>3i looks up the <code>cageid</code> entry for B, and lookup corresponding runtime function pointer for <code>cageid</code></li> <li>3i directly invokes the function pointer, re-entering the target Wasm instance through Wasmtime\u2019s runtime context.</li> </ol> <p>Dispatch Inside Grate:</p> <p>The Wasm entry function (in module) receives a pointer identifying the target handler and dispatches control to the correct per-syscall implementation.</p>"},{"location":"internal/libc/","title":"Modifications Made to glibc and <code>crt1.c</code>","text":""},{"location":"internal/libc/#1-changes-to-glibc","title":"1. Changes to glibc","text":""},{"location":"internal/libc/#11-changing-the-system-call-mechanism","title":"1.1 Changing the System Call Mechanism","text":"<p>The system call mechanism was modified to route system calls through <code>rawposix</code> instead of directly invoking the kernel. The new format for making system calls is structured as follows:</p> <pre><code>MAKE_SYSCALL(syscallnum, \"syscall|callname\", arg1, arg2, arg3, arg4, arg5, arg6)\n</code></pre> <p>For each system call file in glibc, a header file named <code>syscall-template.h</code> was added with the following content:</p> <pre><code>#include &lt;sys/syscall.h&gt;\n#include &lt;stdint.h&gt;    // For uint64_t\n#include &lt;unistd.h&gt;\n#include &lt;lind_syscall.h&gt;\n\n// Define NOTUSED for unused arguments\n#define NOTUSED 0xdeadbeefdeadbeefULL\n\n// Macro to create a syscall and redirect it to rawposix\n#define MAKE_SYSCALL(syscallnum, callname, arg1, arg2, arg3, arg4, arg5, arg6) \\\n    lind_syscall(syscallnum, \\\n                 (unsigned long long)(callname), \\\n                 (unsigned long long)(arg1), \\\n                 (unsigned long long)(arg2), \\\n                 (unsigned long long)(arg3), \\\n                 (unsigned long long)(arg4), \\\n                 (unsigned long long)(arg5), \\\n                 (unsigned long long)(arg6))\n</code></pre> <p>The <code>MAKE_SYSCALL</code> macro redirects system calls to rawposix, providing an interface for syscall handling in this context.</p>"},{"location":"internal/libc/#12-eliminating-assembly-code","title":"1.2 Eliminating Assembly Code","text":"<p>Since WebAssembly (WASM) does not support assembly, all assembly-related components in glibc were removed: - Inline assembly code was rewritten in C. - Files ending in <code>.s</code> were converted to <code>.c</code> files, and their functionalities were reimplemented in C.</p>"},{"location":"internal/libc/#13-handling-automatically-generated-s-files","title":"1.3 Handling Automatically Generated <code>.s</code> Files","text":"<p>glibc automatically generates <code>.s</code> files for certain system calls. To address this: - The script responsible for generating these <code>.s</code> files was disabled. - The corresponding system calls were manually implemented in C and placed in appropriate <code>.c</code> files.</p>"},{"location":"internal/libc/#14-additional-modifications","title":"1.4 Additional Modifications","text":"<ul> <li>Disable <code>_dl_mcount_wrapper_check</code>: This functionality was disabled as it is not required in the WASI environment.</li> <li>Change <code>initial-exec</code> to <code>local-exec</code>: All instances of <code>initial-exec</code> were replaced with <code>local-exec</code> to align with WebAssembly's threading and memory model.</li> <li>Implement <code>BYTE_COPY_FWD</code> and <code>BYTE_COPY_BWD</code>: These functions were implemented in C without relying on <code>memcpy</code> or <code>memmove</code> to ensure compatibility with the WASM environment.</li> <li>Disable <code>attribute_relro</code>: The original C code places the vtable into the <code>relro</code> section in the binary. Since WebAssembly binaries do not have this section, the attribute was disabled.</li> </ul>"},{"location":"internal/libc/#15-replacing-auto-generated-assembly-in-i386-sysdeps","title":"1.5 Replacing Auto-Generated Assembly in <code>i386</code> Sysdeps","text":"<p>In upstream glibc, the <code>sysdeps/unix/sysv/linux/i386</code> directory (including <code>i686</code>) uses build-time rules to generate <code>.S</code> assembly files that implement syscall stubs and other low-level glue. This relies on a native assembler and does not work when targeting WebAssembly.</p> <p>In this tree, the syscall implementations that glibc normally provides via generated <code>.S</code> files are replaced with C implementations in the <code>i386</code> / <code>i686</code> sysdeps. These implementations use <code>MAKE_LEGACY_SYSCALL</code>, which is the syscall wrapper used in the current lind-glibc tree.</p> <p>System calls issued via <code>MAKE_LEGACY_SYSCALL</code> pass through the Wasmtime runtime layer and the 3i routing layer before being forwarded to <code>rawposix</code>, reflecting the intended Lind/WASM execution model.</p> <p>As a result of these changes, glibc no longer generates or compiles assembly for the <code>i386</code> sysdeps. The library is built using a Lind-specific glibc build configuration targeting WASM, with all changes localized to the <code>i386</code> Linux sysdeps.</p>"},{"location":"internal/libc/#2-modifications-and-additions-to-crt1c-for-wasi","title":"2. Modifications and Additions to <code>crt1.c</code> for WASI","text":""},{"location":"internal/libc/#21-wasi-specific-function-wrappers","title":"2.1 WASI-Specific Function Wrappers","text":"<ul> <li>Wrappers for WASI Snapshot Preview 1 APIs:   Several wrappers were defined for handling WASI <code>args</code> and <code>environ</code> APIs, including:</li> <li><code>__imported_wasi_snapshot_preview1_args_sizes_get</code></li> <li><code>__imported_wasi_snapshot_preview1_args_get</code></li> <li><code>__imported_wasi_snapshot_preview1_environ_get</code></li> <li> <p><code>__imported_wasi_snapshot_preview1_environ_sizes_get</code></p> </li> <li> <p>Implementation:   These wrappers use the following attribute for integration:   <pre><code>__attribute__((\n    __import_module__(\"wasi_snapshot_preview1\"),\n    __import_name__(\"function_name\")\n));\n</code></pre></p> </li> <li> <p>Purpose: Enables access to WASI-specific argument and environment APIs.</p> </li> </ul>"},{"location":"internal/libc/#22-environment-initialization","title":"2.2 Environment Initialization","text":"<ul> <li>Added <code>__wasi_initialize_environ</code>:   This function initializes the environment variables by:</li> <li>Using <code>__wasi_environ_sizes_get</code> to determine the size of environment data.</li> <li> <p>Using <code>__wasi_environ_get</code> to populate the <code>environ</code> array.</p> </li> <li> <p>Fallback Logic:   If the environment is empty, the program:</p> </li> <li>Falls back to a static empty environment (<code>empty_environ</code>).</li> <li>Exits with an appropriate error code when necessary.</li> </ul>"},{"location":"internal/libc/#23-thread-and-tls-setup","title":"2.3 Thread and TLS Setup","text":"<ul> <li>Added Calls to <code>__libc_setup_tls</code> and <code>__wasi_init_tp</code>:   These functions are included in <code>_start</code> to set up thread-local storage (TLS) and thread pointers, which are essential for multithreading or TLS-dependent code.</li> </ul>"},{"location":"internal/libc/#24-main-function-handling","title":"2.4 Main Function Handling","text":"<ul> <li>Modified <code>__main_void</code> to Handle WASI Arguments:</li> <li>Initializes command-line arguments by:<ul> <li>Using <code>__wasi_args_sizes_get</code> to determine argument buffer sizes.</li> <li>Using <code>__wasi_args_get</code> to populate <code>argv</code> and <code>argv_buf</code>.</li> </ul> </li> <li> <p>Passes the initialized arguments to <code>__main_argc_argv</code>.</p> </li> <li> <p>Weak Symbol for <code>__main_argc_argv</code>:   Defined as a weak symbol to allow the dynamic linker to handle cases where no <code>main</code> function exists (e.g., in reactor-style applications).</p> </li> </ul>"},{"location":"internal/libc/#25-error-handling","title":"2.5 Error Handling","text":"<ul> <li>Specific Exit Codes:</li> <li> <p>Introduced <code>_Exit(EX_OSERR)</code> and <code>_Exit(EX_SOFTWARE)</code> for different error scenarios, aligning with <code>sysexits.h</code> standards.</p> </li> <li> <p>Purpose: Provides descriptive and standard error handling for memory allocation or initialization failures.</p> </li> </ul>"},{"location":"internal/libc/#26-placeholder-functions","title":"2.6 Placeholder Functions","text":"<ul> <li>Added Stub for <code>__wasm_call_dtors</code>:</li> <li> <p>An empty placeholder function for future destructor handling.</p> </li> <li> <p>Added Stub for <code>__wasi_proc_exit</code>:</p> </li> <li>A placeholder function for handling process exits in WASI.</li> </ul>"},{"location":"internal/libc/#27-memory-allocation-for-argv-and-environ","title":"2.7 Memory Allocation for <code>argv</code> and <code>environ</code>","text":"<ul> <li>Allocates memory dynamically for:</li> <li>Argument buffers (<code>argv_buf</code>) and pointers (<code>argv</code>).</li> <li>Environment buffers (<code>environ_buf</code>) and pointers (<code>environ_ptrs</code>).</li> <li>Uses <code>malloc</code> and <code>calloc</code> with robust error handling to prevent memory allocation failures.</li> </ul>"},{"location":"internal/memory/","title":"Memory Management and Vmmap","text":""},{"location":"internal/memory/#what-is-a-vmmap","title":"What is a Vmmap?","text":"<p>A vmmap is a tool for managing a process\u2019s memory layout within an operating system. It provides detailed insights into allocated memory regions, including the heap, stack, and memory-mapped files. Additionally, it displays access permissions (read-only, read-write, executable), memory region boundaries, sizes, and any mapped files.</p>"},{"location":"internal/memory/#motivation","title":"Motivation","text":"<p>Wasmtime traditionally manages memory using WebAssembly\u2019s linear memory model, where each instance gets a contiguous memory block divided into 64 KiB pages. This memory can grow or shrink dynamically within defined constraints. Since Lind emulates processes as cages within a single address space, tracking allocated memory regions per cage is essential.</p> <p>Attempts to provide POSIX-like interfaces for WASM, such as wasi-libc and emscripten, rely on WASM's memory.grow feature to expand available memory. Both implement custom malloc() functions that use memory.grow to extend the heap while preventing system mmap operations. Alternatively, they simulate file-backed mmap by invoking memory.grow and manually copying file contents into the allocated region.</p> <p>To address this, we eschew memory.grow and integrate a vmmap system into Lind that more closely resembles POSIX-based memory management. This allows proper implementation of syscalls like brk(), mmap(), and mprotect() for memory allocation, deallocation, and permission management. It also ensures accurate memory region copying when forking cages. Further justification for the need for a vmmap is provided in the later section \"Why the Vmmap is Necessary.\"</p>"},{"location":"internal/memory/#vmmap-implementation-overview","title":"Vmmap Implementation Overview","text":"<p>The vmmap internally uses a discrete interval tree to manage memory regions efficiently. This data structure functions similarly to a balanced tree, enabling fast lookups, insertions, and deletions of memory mappings. It supports optimized allocation by quickly identifying contiguous free memory blocks. Additionally, it ensures proper handling of updates, such as modifying protections or removing entries, by correctly managing overlapping regions through splitting or merging. Other key features include address range queries to validate memory access and enforce permissions, as well as functions for translating addresses between user space and system memory.</p> <p>Internal Operation Details: All vmmap operations use page numbers internally, not byte addresses, aligning with the underlying system memory model for efficient address space management. When operations modify only part of an existing memory entry, the system automatically creates new entries for unchanged portions while preserving their original attributes, ensuring fine-grained control over memory regions.</p>"},{"location":"internal/memory/#why-the-vmmap-is-necessary","title":"Why the Vmmap is Necessary","text":"<p>Without a vmmap, syscalls like mmap() and munmap() could still be implemented using a greedy approach with memory.grow, similar to how other systems simulate file-backed mmap, as described above. However, this method would be unsuitable for multi-processing and would violate POSIX compliance, as we explain in this section.</p>"},{"location":"internal/memory/#fork","title":"fork()","text":"<p>The fork() system call requires duplicating the parent process\u2019s memory space for the child. Properly replicating memory requires tracking protections and distinguishing shared memory regions. Memory regions possess distinct permissions\u2014either defined at creation or modified through mprotect(). Consequently, a simple bulk memory copy cannot accurately preserve these protections without tracking each region individually. Additionally, memory regions mapped with MAP_SHARED must be tracked individually to ensure proper sharing between cages. Without a mechanism like a vmmap, there is no way to distinguish shared regions from non-shared ones. By tracking shared regions, we can then use mremap when forking to create a shareable mapping between cages.</p>"},{"location":"internal/memory/#brk","title":"brk()","text":"<p>The brk() system call expands the heap linearly, ensuring contiguous allocation as required by libc and other libraries. Many functions, including malloc(), depend on this guarantee. Without a vmmap, memory allocation could use the aforementioned greedy approach, but this might interleave heap regions with other mappings created by mmap(), violating POSIX compliance and leading to library failures.</p>"},{"location":"internal/memory/#mmapmunmapmprotect","title":"mmap()/munmap()/mprotect()","text":"<p>It's necessary to manage memory allocated or modified using these calls to support the proper functiong of fork() and brk() as mentioned above.</p>"},{"location":"internal/memory/#additional-benefits","title":"Additional Benefits:","text":"<ul> <li>Reduced fragmentation: Without memory tracking, greedy allocation wastes space by failing to reuse deallocated pages. This is particularly crucial since cages are limited to 4GB of address space.</li> <li>Improved memory safety: Heap overflows are less likely to impact valid mappings, as heaps and other memory regions remain isolated unless explicitly mapped with MAP_FIXED.</li> </ul>"},{"location":"internal/memory/#system-calls","title":"System Calls","text":"<p>The implementation of mmap, brk, and sbrk interacts with vmmap, ensuring efficient allocation, deallocation, and permission enforcement for different types of memory regions.</p>"},{"location":"internal/memory/#mmap","title":"mmap()","text":"<p>mmap provides a mechanism for mapping memory regions with specific properties, such as anonymous memory for heap growth or file-backed mappings for shared memory. It allows fine-grained control over memory protection (PROT_READ, PROT_WRITE), allocation strategies (MAP_PRIVATE, MAP_SHARED), and address-space placement (MAP_FIXED). To ensure that memory mappings remain manageable, mmap works with vmmap to search for available memory regions. When vmmap searches for a free range, it always starts from the bottom of the address space and grows upwards. This minimizes fragmentation and avoids conflicts with the heap, which is placed at the top of memory and grows downwards.</p> <p>How It Works</p> <ol> <li>Memory Region Identification:<ul> <li>If MAP_FIXED is not set, vmmap searches for a suitable free memory region in strict mode, rejecting any overlapping entries.</li> <li>If MAP_FIXED is specified, the requested address is used directly and may result in overwriting existing entries.</li> </ul> </li> <li>Memory Protection and Flags Enforcement:<ul> <li>Only a restricted set of flags are allowed to prevent unintended behavior.</li> <li>Execution permissions (PROT_EXEC) are explicitly disallowed for security reasons.</li> </ul> </li> <li>Address Translation and System Invocation:<ul> <li>The selected virtual address is translated into a system address. -The actual mmap operation is invoked on the host system with MAP_FIXED to ensure deterministic placement.</li> </ul> </li> <li>Updating the vmmap:<ul> <li>If the mapping is successful, vmmap is updated to reflect the allocated region, including its permissions and backing type (anonymous or file-backed).</li> <li>When new entries overlap with existing ones, they replace overlapping entries rather than merging them. New entry attributes completely override old attributes in the overlapping region, with automatic splitting for partial overlaps.</li> </ul> </li> </ol>"},{"location":"internal/memory/#munmap","title":"munmap()","text":"<p>munmap is used to release memory mappings previously allocated via mmap. Unlike traditional implementations that return memory to the OS, Lind\u2019s munmap only marks the region as inaccessible by setting it to PROT_NONE, while retaining it within the process's address space.</p> <p>How It Works</p> <ol> <li>Address Validation:<ul> <li>The target address must be aligned to page boundaries.</li> <li>The region must exist within vmmap and must not contain protected memory.</li> </ul> </li> <li>Memory Protection Adjustment:<ul> <li>Instead of actually deallocating memory, the affected region is marked as PROT_NONE. The memory remains allocated but becomes inaccessible.</li> </ul> </li> <li>Updating vmmap:<ul> <li>The mapping entry is removed from vmmap, ensuring that the region is available for future allocations.</li> </ul> </li> </ol>"},{"location":"internal/memory/#mprotect","title":"mprotect()","text":"<p>mprotect() allows modification of protection flags for existing memory mappings, enabling or disabling read, write, and execute permissions for specified regions.</p> <p>How It Works</p> <ol> <li>Protection Change:<ul> <li>Only the requested protection field is modified; all other entry metadata remains unchanged, including <code>maxprot</code>, backing type, flags, and other attributes.</li> </ul> </li> <li>Address Alignment:<ul> <li>The target address and length must be page-aligned.</li> <li>The region must correspond to an existing memory mapping in vmmap.</li> </ul> </li> <li>Updating vmmap:<ul> <li>The protection attributes of the affected vmmap entry are updated without affecting other region properties.</li> </ul> </li> </ol>"},{"location":"internal/memory/#brksbrk","title":"brk()/sbrk()","text":"<p>brk and sbrk provide a mechanism to dynamically expand or shrink the heap by adjusting the program break. This is essential for memory allocation routines such as malloc, which rely on contiguous heap growth. In Lind, the heap is always placed at the top of the memory space, right after the stack region, and grows downwards. This is opposite to the direction in which mmap allocates memory (bottom-up), ensuring that mmap-allocated regions do not typically interfere with heap growth.</p> <p>How It Works</p> <ol> <li>Tracking the Program Break:<ul> <li>The program break corresponds to the end of the heap region in vmmap.</li> <li>sbrk(0) returns the current break, while sbrk(N) attempts to increase the heap by N bytes.</li> </ul> </li> <li>Heap Expansion:<ul> <li>When increasing the program break, the system first verifies that the requested range does not overlap with existing mappings.</li> <li>If space is available, the permissions of the new memory region are updated to match the heap\u2019s permissions.</li> <li>The vmmap entry is updated to reflect the new program break.</li> </ul> </li> <li>Heap Shrinking:<ul> <li>If the program break is decreased, memory beyond the new limit is marked as inaccessible (PROT_NONE) instead of being deallocated immediately, similar to munmap.</li> <li>The vmmap entry is updated accordingly.</li> </ul> </li> </ol>"},{"location":"internal/multiprocess-support/","title":"Multi-Process Support in Lind-Wasm","text":""},{"location":"internal/multiprocess-support/#multi-processing-via-asyncify","title":"Multi-processing via Asyncify","text":"<p>The way multi-process (specifically clone_syscall, exit_syscall and longjmp) works in lind-wasm heavily depends on Asyncify from Binaryen. So let\u2019s first introduce how Asyncify works on WebAssembly.\\ So Asyncify is a second-time compilation that adds some logic to the existing compiled file.\\ The Asyncify works by having a few global variables that define the current execution status. One global variable is to describe the current status of stack unwind/rewind. If current_state is set to unwind, that means the current process is undergoing stack unwind, and if current_state is set to rewind, that means the current process is undergoing stack rewind, and if current_state is set to normal, that means the current process is working normally, just like no Asyncify has applied to it.\\ \\ For example, suppose there is a program looks like this:</p> <pre><code>int funcA()\n{\n    int a;\n    int b;\n\n    for... {\n        ...do some work...\n    }\n\n    funcB();\n\n    ...do some work...\n}\n\nint funcB()\n{\n    ...do some work\n      imported_wasm_functionC();\n}\n</code></pre> <p>After applying Asyncify, it may become something like this:</p> <pre><code>int funcA()\n{\n    if(current_state == rewind) {\n        restore_functionA_context();\n    }\n    if(current_state == normal) {\n        int a;\n        int b;\n\n        for... {\n            ...do some work...\n        }\n    }\n    if(last_unwind_return_is_here)\n    {\n        funcB();\n        if(current_state == unwind) {\n            save_functionA_context();\n            return;\n        }\n    }\n\n    if(current_state == normal) {\n        ...do some work...\n    }\n}\n\nint funcB()\n{\n    if(current_state == rewind) {\n        restore_functionB_context();\n    }\n    if(current_state == normal) {\n        if(current_state == normal) {\n            ...do some work\n        }\n    }\n\n    if(last_unwind_return_is_here) {\n        imported_wasm_functionC();\n        if(current_state == unwind) {\n            save_functionB_context();\n            return;\n        }\n    }\n}\n</code></pre> <p>So Asyncify basically adds an if statement for all the normal user code and only executes the user code if current_state is normal. After a function has been executed, it will check if current_state is set to unwind. If that is the case, the function context will be saved and the function will return immediately. When rewind happens later, the function context will be restored at the beginning of the function.\\ \\ Besides these, Asyncify also has four functions that control the global current_state.\\ Asyncify_unwind_start: Once called, set current_state to unwind and return\\ Asyncify_unwind_stop: Once called, set current_state to normal and return\\ Asyncify_rewind_start: Once called, set current_state to rewind and return\\ Asyncify_rewind_stop: Once called, set current_state to normal and return\\ Asyncify_unwind_start and Asyncify_rewind_start also takes an additional argument that specifies where to store/retrieve the unwind_data (i.e. function context).</p> <p>Such transformation from Asyncify allows you to freely navigate the callstack of a process, but with the cost of largely increased binary size, and slightly decreased performance (from a bunch of extra if statements added by Asyncify).</p>"},{"location":"internal/multiprocess-support/#fork","title":"fork()","text":"<p>The fork syscall is built up on Asyncify. When fork is called, the whole wasm process would undergo unwind and rewind. But the unwind_data (function context) is copied once unwind is done. The unwind_data could basically be viewed as a snapshot of the callstack (with the unwind_data, we can restore the wasm process to the state when unwind_data is captured). With such a powerful mechanism, the implementation of the fork is pretty straightforward: once we capture the snapshot of the parent process callstack, we can let the child do the rewind with the unwind_data from parent, and the child will be able to return to the exact state when parent calls fork. Threading creation is very similar to this, except that the memory is shared between parent and child.</p>"},{"location":"internal/multiprocess-support/#exit-and-exec","title":"exit() and exec()","text":"<p>Exit syscall is currently also built on Asyncify, by performing the unwind on the process, then instead of doing rewinding, the process can just return.</p> <p>Exec syscall is built upon Exit syscall: instead of returning directly after unwind is finished, a new wasm instance is created with the supplied binary path.</p>"},{"location":"internal/multiprocess-support/#setjmp-and-longjmp","title":"setjmp() and longjmp()","text":"<p>Setjmp and longjmp implementation is also very similar to fork: When setjmp is called, the process will undergo unwind and rewind, leaving an unwind_data (callstack snapshot). The unwind_data is saved somewhere. When later the process calls longjmp and specifies a restore to the previous state, the process first will unwind, after unwind is finished, its unwind_data will be replaced by the old unwind_data generated when setjmp is called. Then after rewind, the process can restore to its previous state. </p>"},{"location":"internal/multiprocess-support/#wait","title":"wait()","text":"<p>Last we have our wait_syscall which is implemented purely in rawposix and does not use Asyncify at all. Wait_syscall works by maintaining a zombie relationship in the cage struct: when a cage exits, it will insert itself into the parent\u2019s zombie list. Therefore, the parent can simply check its zombie list when doing the wait syscall, and retrieve the first zombie in the list (first in first out).</p>"},{"location":"internal/rawposix/","title":"Introduction","text":""},{"location":"internal/rawposix/#overview-of-rawposix","title":"Overview of RawPOSIX","text":"<p>RawPOSIX is a critical component of the Lind Project, designed to provide a POSIX-compliant interface for applications running within a microvisor environment. The primary goal of RawPOSIX is to enable the execution of both legacy and modern multi-processes\u2019 applications safely and efficiently within the same address space without any modification to source code and perform the same behavior with applications running on native Linux.</p>"},{"location":"internal/rawposix/#purpose-and-scope-of-rawposix","title":"Purpose and Scope of RawPOSIX","text":"<p>The purpose of the RawPOSIX project is to provide an in-process OS while isolating them. By offering a POSIX-like interface, RawPOSIX is an interface implemented on top of standard POSIX (Linux) system calls. It provides functionalities such as signals, fork/exec, threading, file system operations, and networking. Additionally, RawPOSIX manages file descriptors (FDs), threads, and other resources independently for each cage, ensuring proper isolation and resource handling. This is particularly beneficial for legacy applications that rely on POSIX standards.</p> <p>The scope of RawPOSIX encompasses several key areas: - System Call API: Implementing a set of raw POSIX system calls that redirect low level operations to kernel and a set of userspace system calls based on POSIX standard to cover process management, network operations, and memory management. - Cage Structure: A \"cage\" data structure in RawPOSIX is designed to handle per-process information while providing required memory management. - Testing and Validation: Providing a testing framework to ensure the reliability and correctness of the RawPOSIX implementation.</p>"},{"location":"internal/rawposix/#key-components-and-files","title":"Key Components and Files","text":"<p>The RawPOSIX repository is organized into several important folders and files that contribute to its functionality: - src/: This directory contains the main Rust codebase for RawPOSIX. It includes the implementation of the syscall API and other core components. - syscalls.rs: This file defines the various system calls supported by RawPOSIX, implementing the logic for each operation. - cage.rs: This file contains definitions of the Cage data structure as well as functions of corresponding operations like creation / insertion / etc. and life cycle management of cages. - tests/: This directory includes test cases and scripts to validate the functionality of RawPOSIX. It ensures that all system calls and cage operations work as expected. - docs/: Documentation files that provide additional context and instructions for setting up and using RawPOSIX.</p>"},{"location":"internal/rawposix/#syscall-api","title":"Syscall API","text":""},{"location":"internal/rawposix/#supported-system-calls","title":"Supported System Calls","text":"<p>In RawPOSIX, raw syscalls are used for direct interactions with the Linux kernel to handle low-level operations, while userspace syscalls serve as abstractions tailored to manage runtime-specific needs (e.g., WASM or Native Client) and ensure isolation through features like per-cage memory management and multi-processing support.</p> <p>For standard system calls, RawPOSIX primarily processes variables passed from the runtime environment and redirects them to the Linux kernel. Beyond supporting standard POSIX system calls (e.g., file system and networking calls), RawPOSIX implements additional features, including: - Memory Management: RawPOSIX provides memory management tailored to the runtime environment, leveraging VMMap-related system calls to enable per-cage memory management. - Process Management: Functions such as wait, waitpid, fork, exec, and signal handling are implemented to support multi-processing. These functions update the cage structure and corresponding data structures as needed, ensuring proper isolation and accurately reflecting the state of processes.</p>"},{"location":"internal/rawposix/#testing","title":"Testing","text":"<p>RawPOSIX employs a comprehensive testing framework to validate its functionality and ensure that all components operate as expected. The testing framework is designed to cover scenarios including both normal usage and error returns. Tests can be found on: lind-wasm/src/RawPOSIX/src/tests/</p>"},{"location":"internal/signals/","title":"Signal Implementation Design Documentation","text":""},{"location":"internal/signals/#1-binary-rewriting","title":"1. Binary Rewriting","text":"<p>As we do not have a way to interrupt a running WebAssembly thread without directly using kernel functions like <code>pthread_kill</code>, our approach inserts signal checks into the Wasm binary. These checks allow the binary to spontaneously callback to the host when the host indicates there are pending signals via an epoch mechanism. The inserted signal checks detect changes in the epoch value, which is managed by Wasmtime\u2019s existing epoch insertion infrastructure at the Cranelift IR level.</p> <p>However, this approach is incompatible with Asyncify, the tool we use to support multi-processing, as Asyncify operates at the Wasm level. To have both epoch-based signal handling and Asyncify-based multi-processing work together, we had two options:</p> <ul> <li>Modifying Wasmtime\u2019s IR-level epoch insertion to make it compatible with Asyncify.</li> <li>Implementing our own Wasm-level epoch insertion.</li> </ul> <p>We chose the latter, as implementing our own Wasm-level epoch insertion is simpler and ensures compatibility with Asyncify automatically.</p>"},{"location":"internal/signals/#2-epoch-management","title":"2. Epoch Management","text":"<p>Epoch management must be carefully handled to ensure correct signal delivery and processing. The epoch can be in one of three states:</p> <ul> <li><code>Normal</code> state: No pending signals.</li> <li><code>Signal</code> state: A pending signal needs to be handled.</li> <li><code>Kill</code> state: The thread needs to be terminated.</li> </ul> <p>When the epoch transitions to either the <code>signal</code> state or the <code>kill</code> state, execution jumps to a callback function in the host. The host then determines the appropriate action based on the signal type. For example, a <code>SIGKILL</code> will immediately terminate the process, whereas other signals may invoke custom guest-defined handlers.</p> <p>During the execution of a signal handler, the epoch must be reset to the <code>normal</code> state to prevent unintended interruptions inside the handler. However, this reset only occurs when there are no more unblocked pending signals. In other words, additional pending signals will continue to interrupt the current signal handler until all the signals are handled.</p> <p>Whenever a new signal is delivered, the following occurs:</p> <ol> <li>If the signal has no disposition set and its default action is to ignore, the signal is dropped immediately and is not added to the pending signal list.</li> <li>If the signal is not blocked, the epoch state is immediately set to the <code>signal</code> state, ensuring the signal is processed promptly.</li> <li>When the epoch is triggered, the host retrieves the first unblocked signal from the pending list and invokes the corresponding signal handler.</li> <li>The epoch state remains in the <code>signal</code> state until all pending (unblocked) signals are processed.</li> <li>New signals received during handler execution are appended to the pending list and will be processed before earlier signals, mirroring Linux\u2019s behavior.</li> </ol> <p>In case of a new signal delivered during the execution of the signal handler, we do not need to take any special consideration. It will be appended to the pending signal list normally and switch epoch to the <code>signal</code> state. This will always make the latest signal being handled first, similar to Linux\u2019s behavior.</p>"},{"location":"internal/signals/#3-epoch-based-signal-handling-with-asyncify","title":"3. Epoch-Based Signal Handling with Asyncify","text":"<p>One key challenge in integrating epoch-based signal handling with Asyncify is ensuring compatibility, particularly when the system is in rewind state. If a signal handler interacts with Asyncify, the entire call stack\u2014including the epoch callback function within the host\u2014must be compatible with Asyncify\u2019s transformation logic.</p> <p>To achieve this, we manually apply Asyncify transformation to our host epoch callback function. Since we support recursive signal handling, we must maintain a record of:</p> <ul> <li>The order of executed signal handlers within the call stack.</li> <li>The parameters passed to each handler.</li> </ul> <p>If a signal handler returns due to an Asyncify unwind operation, we must detect this condition and immediately break the loop processing pending signals, returning control to the unwinding call stack.</p> <p>If the epoch callback function is reached while in Asyncify rewind state, we must detect the rewind state and skip the normal epoch handling logic, resuming the call stack by directly invoking the last active signal handler with its remembered parameters.</p>"},{"location":"internal/signals/#4-sigaction-and-sigprocmask","title":"4. <code>sigaction</code> and <code>sigprocmask</code>","text":"<p>The <code>sigaction</code> and <code>sigprocmask</code> syscalls do not need to directly interact with the epoch mechanism. Instead, they can be safely stored in the process\u2019s cage structure until needed by other syscalls. The <code>sigprocmask</code> information is checked when processing pending signals to determine whether a signal should be skipped due to being blocked.</p> <p>A notable aspect of <code>sigprocmask</code> handling is managing signals that are unblocked. If a signal is unblocked while it is still pending, the epoch state should immediately transition to the <code>signal</code> state, similar to when a new signal is received.</p> <p>When a signal handler is executed, we must temporarily block signals specified in the <code>sa_mask</code> field of <code>sigaction</code>. Once the signal handler finishes execution, we restore the signal mask to its previous state, overriding any modifications made during the execution of the signal handler. This behavior is consistent with Linux, which forcibly restores the signal mask after a handler completes\u2014even if <code>sigprocmask</code> was modified inside the handler.</p> <p>By default, the same signal will be blocked during its execution of its handler. Therefore, we explicitly add the same signal to <code>sa_mask</code>, preventing the handler from being re-entered while it is executing. To support <code>SA_NODEFER</code>, we can simply unset the same signal in the mask.</p> <p>We also support <code>SA_RESETHAND</code> by resetting the signal handler to its default state once the signal is handled, ensuring the handler is executed only once.</p>"},{"location":"internal/signals/#5-threads-termination","title":"5. Threads Termination","text":"<p>We introduced the <code>kill</code> state in the epoch mechanism primarily to enable terminating all running threads within a cage when necessary. The <code>kill</code> state uses the same host callback function as the <code>signal</code> state, but it is explicitly checked at the beginning of the callback function to perform a suicide operation if required.</p> <p>To support this, we need to store the epoch handler for each thread in the cage to be able to update the epoch state for all threads simultaneously.</p> <p>The suicide operation is implemented using Wasmtime\u2019s internal trap mechanism. By raising a special trap within the thread, Wasmtime can intercept and distinguish it from regular traps caused by faults such as segmentation faults. If the trap originates from the epoch mechanism, it is ignored, and the WebAssembly instance exits cleanly as if it terminated normally.</p> <p>Thread termination is essential for handling signals like <code>SIGKILL</code> correctly, as <code>SIGKILL</code> must terminate all threads in a process.</p>"},{"location":"internal/signals/#6-main-thread-management","title":"6. Main Thread Management","text":"<p>Since per-thread signals are not currently supported, signal-related structures such as the <code>sigaction</code> state and signal mask state are shared among all threads within a cage. When a signal is delivered, one thread must handle it while the others continue running normally. To achieve this, we designate a main thread responsible for processing all signals.</p> <p>By default, the main thread is the first thread spawned in the cage. However, if the main thread exits while other threads are still running, a new main thread must be selected. In this case, we can simply choose a random running thread as the new main thread.</p>"},{"location":"internal/signals/#todos","title":"TODOs","text":"<ul> <li>Use the new epoch-based method for implementing the exit syscall: Since we already have the infrastructure to terminate all threads within a cage, this mechanism should be applicable for handling the exit syscall. However, a minor issue remains regarding how to properly propagate the exit code upstream, which has not yet been implemented in the existing codebase.</li> <li>Add an epoch check in the host immediately after a syscall completes and before returning to the guest: Linux performs a signal check before transitioning from kernel mode to user mode, and we can adopt a similar approach to align our implementation more closely with Linux. One challenge is ensuring compatibility with Asyncify in the syscall path, as introducing another function in the call stack requires careful manual Asyncify transformation.</li> <li>Support for <code>SIGSTOP</code> and <code>SIGCONT</code>: We intend to support <code>SIGSTOP</code> and <code>SIGCONT</code>, which can be implemented by making the WebAssembly thread sleep and wake up accordingly. This should be straightforward.</li> <li>Enable signal interruption during syscalls: To support signal handling during blocking syscalls, we can modify all blocking syscalls to use a timeout-based version that periodically checks for signals. Additionally, the <code>SA_RESTART</code> flag could be a useful feature to implement in the future.</li> </ul>"},{"location":"internal/wasmtime/","title":"Introduction to Wasmtime","text":""},{"location":"internal/wasmtime/#what-is-wasmtime","title":"What is Wasmtime?","text":"<p>Wasmtime is a standalone JIT-style runtime for WebAssembly, designed for use with WebAssembly System Interface (WASI) and other WASI-inspired environments. It is part of the Bytecode Alliance, an open-source effort to create secure software foundations.</p> <p>Wasmtime can run WebAssembly modules that follow the WASI standard, providing a robust and efficient environment for running WebAssembly outside of the browser.</p>"},{"location":"internal/wasmtime/#getting-started-with-wasmtime","title":"Getting Started with Wasmtime","text":"<p>To get started with Wasmtime, you can download and install it from the official Wasmtime releases page. Follow the installation instructions specific to your operating system.</p>"}]}